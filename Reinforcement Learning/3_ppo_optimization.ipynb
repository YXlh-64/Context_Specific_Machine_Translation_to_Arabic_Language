{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "533a268c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (4.46.0)\n",
      "Requirement already satisfied: accelerate in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: torch in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (2.9.1)\n",
      "Requirement already satisfied: datasets in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (3.1.0)\n",
      "Requirement already satisfied: trl in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (0.12.0)\n",
      "Requirement already satisfied: peft in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (0.7.1)\n",
      "Requirement already satisfied: bitsandbytes in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (0.41.3)\n",
      "Requirement already satisfied: filelock in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (1.2.0)\n",
      "Requirement already satisfied: psutil in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: xxhash in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (3.13.2)\n",
      "Requirement already satisfied: rich in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from trl) (14.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.11)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (1.2.0)\n",
      "Requirement already satisfied: psutil in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: xxhash in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (3.13.2)\n",
      "Requirement already satisfied: rich in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from trl) (14.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.11)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests->transformers) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from rich->trl) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from rich->trl) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests->transformers) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from rich->trl) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from rich->trl) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: comet-ml in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (3.55.0)\n",
      "Requirement already satisfied: unbabel-comet in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (2.2.7)\n",
      "Requirement already satisfied: bert-score in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: sacrebleu in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (0.24.10)\n",
      "Requirement already satisfied: everett<3.2.0,>=1.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (3.1.0)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (4.25.1)\n",
      "Requirement already satisfied: psutil>=5.6.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (7.1.3)\n",
      "Requirement already satisfied: python-box<7.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (6.1.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.32.5)\n",
      "Requirement already satisfied: rich>=13.3.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (14.2.0)\n",
      "Requirement already satisfied: semantic-version>=2.8.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.10.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.1.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.47.0)\n",
      "Requirement already satisfied: simplejson in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (3.20.2)\n",
      "Requirement already satisfied: urllib3>=1.26.8 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.6.2)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.0.1)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (3.1.1)\n",
      "Requirement already satisfied: configobj in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (5.0.9)\n",
      "Requirement already satisfied: entmax<2.0,>=1.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (1.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (0.36.0)\n",
      "Requirement already satisfied: jsonargparse==3.13.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (3.13.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.20.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.4.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (2.3.3)\n",
      "Requirement already satisfied: protobuf<5.0.0,>=4.24.4 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (4.25.8)\n",
      "Requirement already satisfied: pytorch-lightning<3.0.0,>=2.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (2.6.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (1.16.3)\n",
      "Requirement already satisfied: sentencepiece<0.3.0,>=0.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (0.2.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (2.9.1)\n",
      "Requirement already satisfied: torchmetrics<0.11.0,>=0.10.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (0.10.3)\n",
      "Requirement already satisfied: transformers<5.0,>=4.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (4.46.0)\n",
      "Requirement already satisfied: PyYAML>=3.13 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jsonargparse==3.13.1->unbabel-comet) (6.0.3)\n",
      "Requirement already satisfied: portalocker in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (3.2.0)\n",
      "Requirement already satisfied: regex in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (2025.11.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (6.0.2)\n",
      "Requirement already satisfied: filelock in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (25.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (1.2.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.15.2)\n",
      "Requirement already satisfied: comet-ml in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (3.55.0)\n",
      "Requirement already satisfied: unbabel-comet in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (2.2.7)\n",
      "Requirement already satisfied: bert-score in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: sacrebleu in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (0.24.10)\n",
      "Requirement already satisfied: everett<3.2.0,>=1.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (3.1.0)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (4.25.1)\n",
      "Requirement already satisfied: psutil>=5.6.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (7.1.3)\n",
      "Requirement already satisfied: python-box<7.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (6.1.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.32.5)\n",
      "Requirement already satisfied: rich>=13.3.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (14.2.0)\n",
      "Requirement already satisfied: semantic-version>=2.8.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.10.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.1.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.47.0)\n",
      "Requirement already satisfied: simplejson in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (3.20.2)\n",
      "Requirement already satisfied: urllib3>=1.26.8 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.6.2)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.0.1)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (3.1.1)\n",
      "Requirement already satisfied: configobj in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (5.0.9)\n",
      "Requirement already satisfied: entmax<2.0,>=1.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (1.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (0.36.0)\n",
      "Requirement already satisfied: jsonargparse==3.13.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (3.13.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.20.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.4.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (2.3.3)\n",
      "Requirement already satisfied: protobuf<5.0.0,>=4.24.4 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (4.25.8)\n",
      "Requirement already satisfied: pytorch-lightning<3.0.0,>=2.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (2.6.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (1.16.3)\n",
      "Requirement already satisfied: sentencepiece<0.3.0,>=0.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (0.2.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (2.9.1)\n",
      "Requirement already satisfied: torchmetrics<0.11.0,>=0.10.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (0.10.3)\n",
      "Requirement already satisfied: transformers<5.0,>=4.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (4.46.0)\n",
      "Requirement already satisfied: PyYAML>=3.13 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jsonargparse==3.13.1->unbabel-comet) (6.0.3)\n",
      "Requirement already satisfied: portalocker in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (3.2.0)\n",
      "Requirement already satisfied: regex in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (2025.11.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (6.0.2)\n",
      "Requirement already satisfied: filelock in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (25.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (1.2.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.7.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from bert-score) (3.10.8)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (3.13.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (3.11)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.30.0)\n",
      "Requirement already satisfied: setuptools in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (80.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas>=1.4.1->unbabel-comet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas>=1.4.1->unbabel-comet) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas>=1.4.1->unbabel-comet) (2025.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.7.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from bert-score) (3.10.8)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (3.13.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (3.11)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.30.0)\n",
      "Requirement already satisfied: setuptools in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (80.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas>=1.4.1->unbabel-comet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas>=1.4.1->unbabel-comet) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas>=1.4.1->unbabel-comet) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.1->unbabel-comet) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests>=2.18.4->comet-ml) (3.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests>=2.18.4->comet-ml) (2025.11.12)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from rich>=13.3.2->comet-ml) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from rich>=13.3.2->comet-ml) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet-ml) (0.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.6.0->unbabel-comet) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->unbabel-comet) (2.1.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.1->unbabel-comet) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests>=2.18.4->comet-ml) (3.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests>=2.18.4->comet-ml) (2025.11.12)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from rich>=13.3.2->comet-ml) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from rich>=13.3.2->comet-ml) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet-ml) (0.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.6.0->unbabel-comet) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->unbabel-comet) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (3.2.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (3.2.5)\n",
      "Requirement already satisfied: wandb in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (0.23.1)\n",
      "Requirement already satisfied: pandas in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: tqdm in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: click>=8.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (8.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (3.1.45)\n",
      "Requirement already satisfied: packaging in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (25.0)\n",
      "Requirement already satisfied: platformdirs in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (4.5.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (4.25.8)\n",
      "Requirement already satisfied: pydantic<3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (2.12.5)\n",
      "Requirement already satisfied: pyyaml in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (6.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (2.32.5)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (2.47.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pydantic<3->wandb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pydantic<3->wandb) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: wandb in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (0.23.1)\n",
      "Requirement already satisfied: pandas in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: tqdm in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: click>=8.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (8.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (3.1.45)\n",
      "Requirement already satisfied: packaging in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (25.0)\n",
      "Requirement already satisfied: platformdirs in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (4.5.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (4.25.8)\n",
      "Requirement already satisfied: pydantic<3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (2.12.5)\n",
      "Requirement already satisfied: pyyaml in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (6.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (2.32.5)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (2.47.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pydantic<3->wandb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pydantic<3->wandb) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "function '_has_torch_function' already has a docstring",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_28291/223184172.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Check GPU availability\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/torch/__init__.py:1848\u001b[0m\n\u001b[1;32m   1842\u001b[0m __all__\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewaxis\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;66;03m# Define Storage and Tensor classes\u001b[39;00m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m-> 1848\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;66;03m# needs to be after torch.Tensor is defined to avoid circular dependencies\u001b[39;00m\n\u001b[1;32m   1851\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m storage \u001b[38;5;28;01mas\u001b[39;00m storage  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/torch/_tensor.py:22\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_C\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_namedtensor_internals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     check_serializing_named_tensor,\n\u001b[1;32m     16\u001b[0m     is_ellipsis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     update_names,\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moverrides\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     get_default_nowrap_functions,\n\u001b[1;32m     24\u001b[0m     handle_torch_function,\n\u001b[1;32m     25\u001b[0m     has_torch_function,\n\u001b[1;32m     26\u001b[0m     has_torch_function_unary,\n\u001b[1;32m     27\u001b[0m     has_torch_function_variadic,\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     31\u001b[0m _P \u001b[38;5;241m=\u001b[39m ParamSpec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_P\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m _TensorLike \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_TensorLike\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39m_C\u001b[38;5;241m.\u001b[39mTensorBase)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/torch/overrides.py:1765\u001b[0m\n\u001b[1;32m   1761\u001b[0m         msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m nor in mode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_get_current_function_mode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1762\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m-> 1765\u001b[0m has_torch_function \u001b[38;5;241m=\u001b[39m _add_docstr(\n\u001b[1;32m   1766\u001b[0m     _has_torch_function,\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Check for __torch_function__ implementations in the elements of an iterable\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m \u001b[38;5;124;03m    or if a __torch_function__ mode is enabled.  Considers exact ``Tensor`` s\u001b[39;00m\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;124;03m    and ``Parameter`` s non-dispatchable.  Use this to guard a call to\u001b[39;00m\n\u001b[1;32m   1770\u001b[0m \u001b[38;5;124;03m    :func:`handle_torch_function`; don't use it to test if something\u001b[39;00m\n\u001b[1;32m   1771\u001b[0m \u001b[38;5;124;03m    is Tensor-like, use :func:`is_tensor_like` instead.\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;124;03m    Arguments\u001b[39;00m\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;124;03m    ---------\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;124;03m    relevant_args : iterable\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;124;03m        Iterable or arguments to check for __torch_function__ methods.\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;124;03m    bool\u001b[39;00m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;124;03m        True if any of the elements of relevant_args have __torch_function__\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;124;03m        implementations, False otherwise.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;124;03m    See Also\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;124;03m    ________\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;124;03m    torch.is_tensor_like\u001b[39;00m\n\u001b[1;32m   1784\u001b[0m \u001b[38;5;124;03m        Checks if something is a Tensor-like, including an exact ``Tensor``.\u001b[39;00m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m,\n\u001b[1;32m   1786\u001b[0m )\n\u001b[1;32m   1788\u001b[0m has_torch_function_unary \u001b[38;5;241m=\u001b[39m _add_docstr(\n\u001b[1;32m   1789\u001b[0m     _has_torch_function_unary,\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Special case of `has_torch_function` for single inputs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m,\n\u001b[1;32m   1797\u001b[0m )\n\u001b[1;32m   1799\u001b[0m has_torch_function_variadic \u001b[38;5;241m=\u001b[39m _add_docstr(\n\u001b[1;32m   1800\u001b[0m     _has_torch_function_variadic,\n\u001b[1;32m   1801\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Special case of `has_torch_function` that skips tuple creation.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m,\n\u001b[1;32m   1811\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: function '_has_torch_function' already has a docstring"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "function '_has_torch_function' already has a docstring",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run setup from config notebook\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0_config_setup.ipynb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/IPython/core/interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/IPython/core/magics/execution.py:741\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m preserve_keys(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39muser_ns, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    740\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m--> 741\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39msafe_execfile_ipy(filename, raise_exceptions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;66;03m# Control the response to exit() calls made by the script being run\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3005\u001b[0m, in \u001b[0;36mInteractiveShell.safe_execfile_ipy\u001b[0;34m(self, fname, shell_futures, raise_exceptions)\u001b[0m\n\u001b[1;32m   3003\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_cell(cell, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, shell_futures\u001b[38;5;241m=\u001b[39mshell_futures)\n\u001b[1;32m   3004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_exceptions:\n\u001b[0;32m-> 3005\u001b[0m     result\u001b[38;5;241m.\u001b[39mraise_error()\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39msuccess:\n\u001b[1;32m   3007\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/IPython/core/interactiveshell.py:308\u001b[0m, in \u001b[0;36mExecutionResult.raise_error\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_before_exec\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_in_exec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_in_exec\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/tmp/ipykernel_28291/223184172.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Check GPU availability\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/torch/__init__.py:1848\u001b[0m\n\u001b[1;32m   1842\u001b[0m __all__\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewaxis\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;66;03m# Define Storage and Tensor classes\u001b[39;00m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m-> 1848\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;66;03m# needs to be after torch.Tensor is defined to avoid circular dependencies\u001b[39;00m\n\u001b[1;32m   1851\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m storage \u001b[38;5;28;01mas\u001b[39;00m storage  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/torch/_tensor.py:22\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_C\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_namedtensor_internals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     check_serializing_named_tensor,\n\u001b[1;32m     16\u001b[0m     is_ellipsis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     update_names,\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moverrides\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     get_default_nowrap_functions,\n\u001b[1;32m     24\u001b[0m     handle_torch_function,\n\u001b[1;32m     25\u001b[0m     has_torch_function,\n\u001b[1;32m     26\u001b[0m     has_torch_function_unary,\n\u001b[1;32m     27\u001b[0m     has_torch_function_variadic,\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     31\u001b[0m _P \u001b[38;5;241m=\u001b[39m ParamSpec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_P\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m _TensorLike \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_TensorLike\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39m_C\u001b[38;5;241m.\u001b[39mTensorBase)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/torch/overrides.py:1765\u001b[0m\n\u001b[1;32m   1761\u001b[0m         msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m nor in mode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_get_current_function_mode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1762\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m-> 1765\u001b[0m has_torch_function \u001b[38;5;241m=\u001b[39m _add_docstr(\n\u001b[1;32m   1766\u001b[0m     _has_torch_function,\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Check for __torch_function__ implementations in the elements of an iterable\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m \u001b[38;5;124;03m    or if a __torch_function__ mode is enabled.  Considers exact ``Tensor`` s\u001b[39;00m\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;124;03m    and ``Parameter`` s non-dispatchable.  Use this to guard a call to\u001b[39;00m\n\u001b[1;32m   1770\u001b[0m \u001b[38;5;124;03m    :func:`handle_torch_function`; don't use it to test if something\u001b[39;00m\n\u001b[1;32m   1771\u001b[0m \u001b[38;5;124;03m    is Tensor-like, use :func:`is_tensor_like` instead.\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;124;03m    Arguments\u001b[39;00m\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;124;03m    ---------\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;124;03m    relevant_args : iterable\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;124;03m        Iterable or arguments to check for __torch_function__ methods.\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;124;03m    bool\u001b[39;00m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;124;03m        True if any of the elements of relevant_args have __torch_function__\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;124;03m        implementations, False otherwise.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;124;03m    See Also\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;124;03m    ________\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;124;03m    torch.is_tensor_like\u001b[39;00m\n\u001b[1;32m   1784\u001b[0m \u001b[38;5;124;03m        Checks if something is a Tensor-like, including an exact ``Tensor``.\u001b[39;00m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m,\n\u001b[1;32m   1786\u001b[0m )\n\u001b[1;32m   1788\u001b[0m has_torch_function_unary \u001b[38;5;241m=\u001b[39m _add_docstr(\n\u001b[1;32m   1789\u001b[0m     _has_torch_function_unary,\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Special case of `has_torch_function` for single inputs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m,\n\u001b[1;32m   1797\u001b[0m )\n\u001b[1;32m   1799\u001b[0m has_torch_function_variadic \u001b[38;5;241m=\u001b[39m _add_docstr(\n\u001b[1;32m   1800\u001b[0m     _has_torch_function_variadic,\n\u001b[1;32m   1801\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Special case of `has_torch_function` that skips tuple creation.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m,\n\u001b[1;32m   1811\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: function '_has_torch_function' already has a docstring"
     ]
    }
   ],
   "source": [
    "# Run setup from config notebook\n",
    "%run 0_config_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00825e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Notebook kernel reset complete\n"
     ]
    }
   ],
   "source": [
    "# Reset the notebook kernel to clear corrupted state from sys.modules deletion\n",
    "%reset -f\n",
    "print(\" Notebook kernel reset complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b14ec42",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "function '_has_torch_function' already has a docstring",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/torch/__init__.py:1848\u001b[0m\n\u001b[1;32m   1842\u001b[0m __all__\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewaxis\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;66;03m# Define Storage and Tensor classes\u001b[39;00m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m-> 1848\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;66;03m# needs to be after torch.Tensor is defined to avoid circular dependencies\u001b[39;00m\n\u001b[1;32m   1851\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m storage \u001b[38;5;28;01mas\u001b[39;00m storage  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/torch/_tensor.py:22\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_C\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_namedtensor_internals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     check_serializing_named_tensor,\n\u001b[1;32m     16\u001b[0m     is_ellipsis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     update_names,\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moverrides\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     get_default_nowrap_functions,\n\u001b[1;32m     24\u001b[0m     handle_torch_function,\n\u001b[1;32m     25\u001b[0m     has_torch_function,\n\u001b[1;32m     26\u001b[0m     has_torch_function_unary,\n\u001b[1;32m     27\u001b[0m     has_torch_function_variadic,\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     31\u001b[0m _P \u001b[38;5;241m=\u001b[39m ParamSpec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_P\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m _TensorLike \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_TensorLike\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39m_C\u001b[38;5;241m.\u001b[39mTensorBase)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/torch/overrides.py:1765\u001b[0m\n\u001b[1;32m   1761\u001b[0m         msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m nor in mode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_get_current_function_mode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1762\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m-> 1765\u001b[0m has_torch_function \u001b[38;5;241m=\u001b[39m _add_docstr(\n\u001b[1;32m   1766\u001b[0m     _has_torch_function,\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Check for __torch_function__ implementations in the elements of an iterable\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m \u001b[38;5;124;03m    or if a __torch_function__ mode is enabled.  Considers exact ``Tensor`` s\u001b[39;00m\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;124;03m    and ``Parameter`` s non-dispatchable.  Use this to guard a call to\u001b[39;00m\n\u001b[1;32m   1770\u001b[0m \u001b[38;5;124;03m    :func:`handle_torch_function`; don't use it to test if something\u001b[39;00m\n\u001b[1;32m   1771\u001b[0m \u001b[38;5;124;03m    is Tensor-like, use :func:`is_tensor_like` instead.\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;124;03m    Arguments\u001b[39;00m\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;124;03m    ---------\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;124;03m    relevant_args : iterable\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;124;03m        Iterable or arguments to check for __torch_function__ methods.\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;124;03m    bool\u001b[39;00m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;124;03m        True if any of the elements of relevant_args have __torch_function__\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;124;03m        implementations, False otherwise.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;124;03m    See Also\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;124;03m    ________\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;124;03m    torch.is_tensor_like\u001b[39;00m\n\u001b[1;32m   1784\u001b[0m \u001b[38;5;124;03m        Checks if something is a Tensor-like, including an exact ``Tensor``.\u001b[39;00m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m,\n\u001b[1;32m   1786\u001b[0m )\n\u001b[1;32m   1788\u001b[0m has_torch_function_unary \u001b[38;5;241m=\u001b[39m _add_docstr(\n\u001b[1;32m   1789\u001b[0m     _has_torch_function_unary,\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Special case of `has_torch_function` for single inputs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m,\n\u001b[1;32m   1797\u001b[0m )\n\u001b[1;32m   1799\u001b[0m has_torch_function_variadic \u001b[38;5;241m=\u001b[39m _add_docstr(\n\u001b[1;32m   1800\u001b[0m     _has_torch_function_variadic,\n\u001b[1;32m   1801\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Special case of `has_torch_function` that skips tuple creation.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m,\n\u001b[1;32m   1811\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: function '_has_torch_function' already has a docstring"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead\n",
    "from trl.core import LengthSampler\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import json\n",
    "\n",
    "# Import LoRA/PEFT for safer training\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "print(\" PPO Optimization - HPC Optimized\")\n",
    "print(f\"   LoRA enabled: {USE_LORA}\")\n",
    "print(f\"   KL Penalty: {KL_PENALTY_COEF}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ef7032",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacef9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading models...\\n\")\n",
    "\n",
    "# Model name (HuggingFace Hub)\n",
    "model_name = \"ModelSpace/GemmaX2-28-9B-v0.1\"\n",
    "\n",
    "# Configure memory allocation for multi-GPU\n",
    "if NUM_GPUS > 1:\n",
    "    max_memory = {i: GPU_MEMORY_PER_DEVICE for i in range(NUM_GPUS)}\n",
    "    max_memory[\"cpu\"] = \"32GB\"\n",
    "else:\n",
    "    max_memory = None\n",
    "\n",
    "# 1. Load SFT model (policy model for PPO)\n",
    "print(f\"Loading SFT model: {model_name}\")\n",
    "\n",
    "policy_tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "if policy_tokenizer.pad_token is None:\n",
    "    policy_tokenizer.pad_token = policy_tokenizer.eos_token\n",
    "policy_tokenizer.padding_side = \"left\"\n",
    "\n",
    "# ===========================\n",
    "# LoRA CONFIGURATION (RECOMMENDED)\n",
    "# ===========================\n",
    "if USE_LORA:\n",
    "    print(\" Using LoRA - Original SFT weights will be PRESERVED\")\n",
    "    \n",
    "    # Configure LoRA\n",
    "    lora_config = LoraConfig(\n",
    "        r=LORA_R,\n",
    "        lora_alpha=LORA_ALPHA,\n",
    "        target_modules=LORA_TARGET_MODULES,\n",
    "        lora_dropout=LORA_DROPOUT,\n",
    "        bias=\"none\",\n",
    "        task_type=TaskType.CAUSAL_LM\n",
    "    )\n",
    "    \n",
    "    # Load base model first\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        max_memory=max_memory,\n",
    "        attn_implementation=ATTN_IMPLEMENTATION if USE_FLASH_ATTENTION else None\n",
    "    )\n",
    "    \n",
    "    # Apply LoRA adapters (original weights stay FROZEN)\n",
    "    base_model = get_peft_model(base_model, lora_config)\n",
    "    base_model.print_trainable_parameters()\n",
    "    \n",
    "    # Wrap with value head for PPO\n",
    "    policy_model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "        base_model,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        is_trainable=True\n",
    "    )\n",
    "    print(\" SFT model loaded with LoRA adapters\")\n",
    "    \n",
    "else:\n",
    "    print(\" Full fine-tuning mode - SFT weights WILL be modified\")\n",
    "    \n",
    "    # Load with value head for PPO (full fine-tuning)\n",
    "    policy_model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        max_memory=max_memory,\n",
    "        attn_implementation=ATTN_IMPLEMENTATION if USE_FLASH_ATTENTION else None\n",
    "    )\n",
    "    print(\" SFT model loaded (full fine-tuning)\")\n",
    "\n",
    "# 2. Load reference model (for KL penalty - always frozen)\n",
    "print(f\"\\nLoading reference model (frozen) for KL computation...\")\n",
    "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    max_memory=max_memory\n",
    ")\n",
    "\n",
    "# Freeze reference model completely\n",
    "for param in ref_model.parameters():\n",
    "    param.requires_grad = False\n",
    "ref_model.eval()\n",
    "print(\" Reference model loaded (frozen)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924ef710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load reward model\n",
    "print(f\"\\nLoading reward model from {REWARD_MODEL_COLD_START}...\")\n",
    "\n",
    "# Load tokenizer\n",
    "rm_tokenizer = AutoTokenizer.from_pretrained(REWARD_MODEL_COLD_START)\n",
    "\n",
    "# Load base model\n",
    "rm_base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    REWARD_BASE_MODEL,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Recreate reward model structure (from notebook 2)\n",
    "from torch import nn\n",
    "\n",
    "class RewardModel(nn.Module):\n",
    "    def __init__(self, base_model, hidden_dim=256, head_type='mlp'):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.head_type = head_type\n",
    "        self.hidden_size = base_model.config.hidden_size\n",
    "        \n",
    "        if head_type == 'linear':\n",
    "            self.reward_head = nn.Linear(self.hidden_size, 1)\n",
    "        elif head_type == 'mlp':\n",
    "            self.reward_head = nn.Sequential(\n",
    "                nn.Linear(self.hidden_size, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.1),\n",
    "                nn.Linear(hidden_dim, 1)\n",
    "            )\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.base_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        hidden_states = outputs.hidden_states[-1]\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = hidden_states.shape[0]\n",
    "        pooled = hidden_states[torch.arange(batch_size), sequence_lengths]\n",
    "        reward = self.reward_head(pooled)\n",
    "        return reward.squeeze(-1)\n",
    "\n",
    "# Create and load weights\n",
    "reward_model = RewardModel(\n",
    "    base_model=rm_base_model,\n",
    "    hidden_dim=RM_HIDDEN_DIM,\n",
    "    head_type=RM_HEAD_TYPE\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(\n",
    "    REWARD_MODEL_COLD_START / \"reward_model.pt\",\n",
    "    map_location='cpu'\n",
    ")\n",
    "reward_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "reward_model.eval()\n",
    "\n",
    "# Freeze reward model\n",
    "for param in reward_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\" Reward model loaded (frozen)\")\n",
    "print(f\"\\nAll models loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acac98e",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6605aa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training prompts (no parallel corpus needed)\n",
    "print(\"Loading training prompts...\")\n",
    "\n",
    "try:\n",
    "    all_data = load_test_prompts(TEST_PROMPTS)\n",
    "    print(f\"Loaded {len(all_data)} test prompts\")\n",
    "except:\n",
    "    # Create sample prompts if file doesn't exist\n",
    "    all_data = [\n",
    "        {\"source\": \"Hello, how are you?\", \"source_lang\": \"en\"},\n",
    "        {\"source\": \"Good morning.\", \"source_lang\": \"en\"},\n",
    "        {\"source\": \"Thank you very much.\", \"source_lang\": \"en\"},\n",
    "        {\"source\": \"Bonjour, comment allez-vous?\", \"source_lang\": \"fr\"},\n",
    "        {\"source\": \"Merci beaucoup.\", \"source_lang\": \"fr\"},\n",
    "    ] * 1000  # Replicate for training\n",
    "    print(f\"Created {len(all_data)} sample prompts\")\n",
    "\n",
    "# Create dataset of prompts for PPO\n",
    "prompts = []\n",
    "for item in all_data[:5000]:  # Adjust size based on resources\n",
    "    prompt = format_translation_prompt(item['source'], item['source_lang'])\n",
    "    prompts.append({\n",
    "        'query': prompt,\n",
    "        'source': item['source'],\n",
    "        'source_lang': item['source_lang']\n",
    "    })\n",
    "\n",
    "# Create HuggingFace dataset\n",
    "dataset = Dataset.from_list(prompts)\n",
    "\n",
    "print(f\"Loaded {len(dataset)} training prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a02bcd1",
   "metadata": {},
   "source": [
    "## PPO Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO configuration - HPC Optimized with Safety Measures\n",
    "ppo_config = PPOConfig(\n",
    "    model_name=model_name,\n",
    "    learning_rate=PPO_LEARNING_RATE,\n",
    "    batch_size=PPO_BATCH_SIZE,\n",
    "    mini_batch_size=PPO_MINI_BATCH_SIZE,\n",
    "    gradient_accumulation_steps=PPO_GRADIENT_ACCUMULATION_STEPS,\n",
    "    ppo_epochs=PPO_EPOCHS,\n",
    "    \n",
    "    # KL penalty to stay close to reference model (INCREASED for safety)\n",
    "    init_kl_coef=KL_PENALTY_COEF,\n",
    "    target_kl=KL_TARGET,\n",
    "    \n",
    "    # PPO clipping\n",
    "    cliprange=CLIP_RANGE,\n",
    "    cliprange_value=VALUE_CLIP_RANGE,\n",
    "    \n",
    "    # GAE parameters\n",
    "    vf_coef=0.1,\n",
    "    gamma=GAMMA,\n",
    "    lam=GAE_LAMBDA,\n",
    "    \n",
    "    # Other settings\n",
    "    seed=SEED,\n",
    "    log_with=\"wandb\" if USE_WANDB else None,\n",
    "    tracker_project_name=WANDB_PROJECT,\n",
    "    tracker_kwargs={\"name\": f\"ppo-coldstart-{'lora' if USE_LORA else 'full'}\"},\n",
    "    \n",
    "    # Optimization settings for HPC\n",
    "    optimize_cuda_cache=True,\n",
    ")\n",
    "\n",
    "print(\"PPO Configuration (HPC Optimized):\")\n",
    "print(f\"  Learning rate: {ppo_config.learning_rate}\")\n",
    "print(f\"  Batch size: {ppo_config.batch_size}\")\n",
    "print(f\"  Mini-batch size: {ppo_config.mini_batch_size}\")\n",
    "print(f\"  KL penalty (init): {ppo_config.init_kl_coef}\")\n",
    "print(f\"  KL target: {ppo_config.target_kl}\")\n",
    "print(f\"  Clip range: {ppo_config.cliprange}\")\n",
    "print(f\"  LoRA: {USE_LORA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37897813",
   "metadata": {},
   "source": [
    "## Reward Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc7ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reward(source_texts, translations):\n",
    "    \"\"\"\n",
    "    Compute rewards for generated translations using the reward model.\n",
    "    \n",
    "    Args:\n",
    "        source_texts: List of source texts\n",
    "        translations: List of generated translations\n",
    "    \n",
    "    Returns:\n",
    "        List of reward scores (tensors)\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    \n",
    "    for source, translation in zip(source_texts, translations):\n",
    "        # Format for reward model\n",
    "        text = f\"Source: {source}\\nTranslation: {translation}\"\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = rm_tokenizer(\n",
    "            text,\n",
    "            max_length=RM_MAX_LENGTH,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ).to(reward_model.base_model.device)\n",
    "        \n",
    "        # Get reward\n",
    "        with torch.no_grad():\n",
    "            reward = reward_model(\n",
    "                inputs['input_ids'],\n",
    "                inputs['attention_mask']\n",
    "            )\n",
    "        \n",
    "        rewards.append(reward.cpu())\n",
    "    \n",
    "    return rewards\n",
    "\n",
    "print(\"Reward function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e013fb0f",
   "metadata": {},
   "source": [
    "## Initialize PPO Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5814993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PPO trainer\n",
    "ppo_trainer = PPOTrainer(\n",
    "    config=ppo_config,\n",
    "    model=policy_model,\n",
    "    ref_model=ref_model,\n",
    "    tokenizer=policy_tokenizer,\n",
    "    dataset=dataset,\n",
    "    data_collator=None,\n",
    ")\n",
    "\n",
    "print(\"PPO Trainer initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87891d6d",
   "metadata": {},
   "source": [
    "## PPO Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39849c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation settings\n",
    "generation_kwargs = {\n",
    "    \"max_new_tokens\": PPO_MAX_NEW_TOKENS,\n",
    "    \"temperature\": PPO_TEMPERATURE,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": policy_tokenizer.pad_token_id,\n",
    "    \"eos_token_id\": policy_tokenizer.eos_token_id,\n",
    "}\n",
    "\n",
    "print(\" Starting PPO training (HPC Optimized with Safety Measures)...\\n\")\n",
    "print(f\"Total steps: {PPO_STEPS}\")\n",
    "print(f\"Max KL threshold: {MAX_KL_THRESHOLD} (will stop if exceeded)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Track metrics for early stopping\n",
    "best_reward = float('-inf')\n",
    "initial_kl = None\n",
    "rewards_history = []\n",
    "kl_history = []\n",
    "\n",
    "# Training loop with safety measures\n",
    "for step, batch in enumerate(tqdm(ppo_trainer.dataloader, total=PPO_STEPS)):\n",
    "    if step >= PPO_STEPS:\n",
    "        break\n",
    "    \n",
    "    # Get queries (prompts)\n",
    "    query_tensors = batch['input_ids']\n",
    "    \n",
    "    # Generate responses (translations)\n",
    "    response_tensors = ppo_trainer.generate(\n",
    "        query_tensors,\n",
    "        return_prompt=False,\n",
    "        **generation_kwargs\n",
    "    )\n",
    "    \n",
    "    # Decode responses\n",
    "    batch_texts = policy_tokenizer.batch_decode(query_tensors, skip_special_tokens=True)\n",
    "    response_texts = policy_tokenizer.batch_decode(response_tensors, skip_special_tokens=True)\n",
    "    \n",
    "    # Extract source texts (for reward computation)\n",
    "    source_texts = []\n",
    "    for text in batch_texts:\n",
    "        if \"English text to Arabic:\" in text:\n",
    "            source = text.split(\"English text to Arabic:\")[1].split(\"\\n\\nArabic translation:\")[0].strip()\n",
    "        elif \"French text to Arabic:\" in text:\n",
    "            source = text.split(\"French text to Arabic:\")[1].split(\"\\n\\nArabic translation:\")[0].strip()\n",
    "        else:\n",
    "            source = text\n",
    "        source_texts.append(source)\n",
    "    \n",
    "    # Compute rewards\n",
    "    rewards = compute_reward(source_texts, response_texts)\n",
    "    \n",
    "    # Run PPO step\n",
    "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
    "    \n",
    "    # Track metrics\n",
    "    current_kl = stats['objective/kl']\n",
    "    current_reward = torch.tensor(rewards).mean().item()\n",
    "    rewards_history.append(current_reward)\n",
    "    kl_history.append(current_kl)\n",
    "    \n",
    "    if initial_kl is None:\n",
    "        initial_kl = current_kl\n",
    "    \n",
    "    # ===========================\n",
    "    # SAFETY CHECK: KL Divergence\n",
    "    # ===========================\n",
    "    if current_kl > MAX_KL_THRESHOLD:\n",
    "        print(f\"\\n SAFETY STOP: KL divergence ({current_kl:.4f}) exceeded threshold ({MAX_KL_THRESHOLD})\")\n",
    "        print(\"   Model is drifting too far from SFT. Stopping to preserve quality.\")\n",
    "        break\n",
    "    \n",
    "    # Log statistics\n",
    "    if step % 10 == 0:\n",
    "        ppo_trainer.log_stats(\n",
    "            stats,\n",
    "            batch,\n",
    "            rewards,\n",
    "            columns_to_log=[\"query\", \"response\"]\n",
    "        )\n",
    "    \n",
    "    # Print progress\n",
    "    if step % 50 == 0:\n",
    "        mean_reward = current_reward\n",
    "        print(f\"\\nStep {step}:\")\n",
    "        print(f\"  Mean reward: {mean_reward:.4f}\")\n",
    "        print(f\"  Mean KL: {current_kl:.4f} (threshold: {MAX_KL_THRESHOLD})\")\n",
    "        print(f\"  Policy loss: {stats['ppo/loss/policy']:.4f}\")\n",
    "        print(f\"  Value loss: {stats['ppo/loss/value']:.4f}\")\n",
    "        \n",
    "        # KL health indicator\n",
    "        kl_ratio = current_kl / MAX_KL_THRESHOLD\n",
    "        if kl_ratio < 0.5:\n",
    "            kl_status = \" Healthy\"\n",
    "        elif kl_ratio < 0.8:\n",
    "            kl_status = \" Moderate\"\n",
    "        else:\n",
    "            kl_status = \" High - approaching limit\"\n",
    "        print(f\"  KL status: {kl_status}\")\n",
    "        \n",
    "        # Show sample\n",
    "        print(f\"\\n  Sample translation:\")\n",
    "        print(f\"  Source: {source_texts[0][:100]}...\")\n",
    "        print(f\"  Generated: {response_texts[0][:100]}...\")\n",
    "        print(f\"  Reward: {rewards[0].item():.4f}\")\n",
    "    \n",
    "    # Save checkpoint periodically\n",
    "    if step > 0 and step % CHECKPOINT_EVERY_N_STEPS == 0:\n",
    "        checkpoint_path = PPO_MODEL_COLD_START / f\"checkpoint-{step}\"\n",
    "        checkpoint_path.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "        if USE_LORA:\n",
    "            # Save only LoRA adapters (small file)\n",
    "            policy_model.pretrained_model.save_pretrained(checkpoint_path)\n",
    "        else:\n",
    "            ppo_trainer.model.save_pretrained(checkpoint_path)\n",
    "        \n",
    "        policy_tokenizer.save_pretrained(checkpoint_path)\n",
    "        print(f\"\\n Checkpoint saved to {checkpoint_path}\")\n",
    "        \n",
    "        # Save training metrics\n",
    "        metrics = {\n",
    "            'step': step,\n",
    "            'mean_reward': float(np.mean(rewards_history[-100:])),\n",
    "            'mean_kl': float(np.mean(kl_history[-100:])),\n",
    "            'max_kl_seen': float(max(kl_history))\n",
    "        }\n",
    "        with open(checkpoint_path / \"metrics.json\", 'w') as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" PPO training complete!\")\n",
    "print(f\"   Final mean reward: {np.mean(rewards_history[-50:]):.4f}\")\n",
    "print(f\"   Final mean KL: {np.mean(kl_history[-50:]):.4f}\")\n",
    "print(f\"   Max KL observed: {max(kl_history):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a344da",
   "metadata": {},
   "source": [
    "## Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d87b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final optimized model\n",
    "print(f\"Saving final model to {PPO_MODEL_COLD_START}...\")\n",
    "\n",
    "PPO_MODEL_COLD_START.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "if USE_LORA:\n",
    "    # Save LoRA adapters only (original SFT weights preserved)\n",
    "    policy_model.pretrained_model.save_pretrained(PPO_MODEL_COLD_START)\n",
    "    print(\" LoRA adapters saved (original SFT weights preserved)\")\n",
    "else:\n",
    "    # Save full model\n",
    "    ppo_trainer.model.save_pretrained(PPO_MODEL_COLD_START)\n",
    "    print(\" Full model saved\")\n",
    "\n",
    "policy_tokenizer.save_pretrained(PPO_MODEL_COLD_START)\n",
    "\n",
    "# Save training info\n",
    "training_info = {\n",
    "    'base_model': model_name,\n",
    "    'reward_model': str(REWARD_MODEL_COLD_START),\n",
    "    'ppo_steps': PPO_STEPS,\n",
    "    'steps_completed': step + 1,\n",
    "    'ppo_config': {\n",
    "        'learning_rate': PPO_LEARNING_RATE,\n",
    "        'kl_penalty': KL_PENALTY_COEF,\n",
    "        'max_kl_threshold': MAX_KL_THRESHOLD,\n",
    "        'clip_range': CLIP_RANGE\n",
    "    },\n",
    "    'lora_config': {\n",
    "        'enabled': USE_LORA,\n",
    "        'r': LORA_R if USE_LORA else None,\n",
    "        'alpha': LORA_ALPHA if USE_LORA else None,\n",
    "        'target_modules': LORA_TARGET_MODULES if USE_LORA else None\n",
    "    },\n",
    "    'final_metrics': {\n",
    "        'mean_reward': float(np.mean(rewards_history[-50:])) if rewards_history else 0,\n",
    "        'mean_kl': float(np.mean(kl_history[-50:])) if kl_history else 0,\n",
    "        'max_kl': float(max(kl_history)) if kl_history else 0\n",
    "    },\n",
    "    'stage': 'cold_start'\n",
    "}\n",
    "\n",
    "with open(PPO_MODEL_COLD_START / \"training_info.json\", 'w') as f:\n",
    "    json.dump(training_info, f, indent=2)\n",
    "\n",
    "print(\" Model saved successfully!\")\n",
    "print(f\"\\nPath: {PPO_MODEL_COLD_START}\")\n",
    "print(f\"LoRA adapters: {USE_LORA}\")\n",
    "print(f\"Original SFT weights preserved: {USE_LORA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c924142",
   "metadata": {},
   "source": [
    "## Test Optimized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb175f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the optimized model\n",
    "print(\"Testing optimized model...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_samples = [\n",
    "    {\"text\": \"Hello, how are you today?\", \"lang\": \"en\"},\n",
    "    {\"text\": \"The weather is beautiful this morning.\", \"lang\": \"en\"},\n",
    "    {\"text\": \"Bonjour, comment allez-vous?\", \"lang\": \"fr\"},\n",
    "]\n",
    "\n",
    "ppo_trainer.model.eval()\n",
    "\n",
    "for i, sample in enumerate(test_samples, 1):\n",
    "    prompt = format_translation_prompt(sample['text'], sample['lang'])\n",
    "    \n",
    "    inputs = policy_tokenizer(prompt, return_tensors=\"pt\").to(ppo_trainer.model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = ppo_trainer.model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            temperature=0.8,\n",
    "            do_sample=True,\n",
    "            pad_token_id=policy_tokenizer.pad_token_id\n",
    "        )\n",
    "    \n",
    "    full_text = policy_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    translation = full_text.split(\"Arabic translation:\")[-1].strip()\n",
    "    \n",
    "    # Compute reward\n",
    "    reward = compute_reward([sample['text']], [translation])[0].item()\n",
    "    \n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(f\"Source ({sample['lang']}): {sample['text']}\")\n",
    "    print(f\"Translation: {translation}\")\n",
    "    print(f\"Reward: {reward:.4f}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if USE_WANDB:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad05695",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "\n",
    "Proceed to **notebook 4** for inference and user feedback collection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7128ab20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (4.46.0)\n",
      "Requirement already satisfied: accelerate in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (1.1.0)\n",
      "Collecting torch\n",
      "  Using cached torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: datasets in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (3.1.0)\n",
      "Requirement already satisfied: trl in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (0.12.0)\n",
      "Requirement already satisfied: peft in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (0.7.1)\n",
      "Requirement already satisfied: bitsandbytes in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (0.41.3)\n",
      "Requirement already satisfied: filelock in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (1.2.0)\n",
      "Requirement already satisfied: psutil in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from accelerate) (7.1.3)\n",
      "Collecting torch\n",
      "  Using cached torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: datasets in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (3.1.0)\n",
      "Requirement already satisfied: trl in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (0.12.0)\n",
      "Requirement already satisfied: peft in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (0.7.1)\n",
      "Requirement already satisfied: bitsandbytes in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (0.41.3)\n",
      "Requirement already satisfied: filelock in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (1.2.0)\n",
      "Requirement already satisfied: psutil in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from accelerate) (7.1.3)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
      "  Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
      "  Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.1 (from torch)\n",
      "  Using cached triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: xxhash in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (3.13.2)\n",
      "Requirement already satisfied: rich in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from trl) (14.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (1.22.0)\n",
      "Collecting triton==3.5.1 (from torch)\n",
      "  Using cached triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: xxhash in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from datasets) (3.13.2)\n",
      "Requirement already satisfied: rich in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from trl) (14.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp->datasets) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.11)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests->transformers) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from rich->trl) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from rich->trl) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: idna>=2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.11)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests->transformers) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from rich->trl) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from rich->trl) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c3c900ebd50>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /packages/56/be/76eaa36c9cd032d3b01b001e2c5a05943df75f26211f68fae79e62f87734/torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c3c900ebd50>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /packages/56/be/76eaa36c9cd032d3b01b001e2c5a05943df75f26211f68fae79e62f87734/torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c3c900e8990>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /packages/56/be/76eaa36c9cd032d3b01b001e2c5a05943df75f26211f68fae79e62f87734/torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c3c900e8990>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /packages/56/be/76eaa36c9cd032d3b01b001e2c5a05943df75f26211f68fae79e62f87734/torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl\u001b[0m\u001b[33m\n",
      "\u001b[0mDownloading torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/899.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m  \u001b[33m0:05:09\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m  \u001b[33m0:05:09\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/594.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m  \u001b[33m0:10:20\u001b[0mm0:00:01\u001b[0m0:03\u001b[0mm\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m  \u001b[33m0:10:20\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/10.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/88.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/954.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/706.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m  \u001b[33m0:00:27\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m  \u001b[33m0:00:27\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m  \u001b[33m0:09:53\u001b[0mm0:00:01\u001b[0m00:03\u001b[0mm━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/193.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m  \u001b[33m0:09:53\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/267.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/288.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m  \u001b[33m0:00:10\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m  \u001b[33m0:00:10\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m  \u001b[33m0:00:10\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/287.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m  \u001b[33m0:00:10\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m  \u001b[33m0:00:11\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/322.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m  \u001b[33m0:00:11\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/39.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m369.0 kB/s\u001b[0m  \u001b[33m0:05:32\u001b[0mm0:00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m369.0 kB/s\u001b[0m  \u001b[33m0:05:32\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/124.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/124.7 MB\u001b[0m \u001b[31m35.2 kB/s\u001b[0m eta \u001b[36m0:54:38\u001b[0mm\n",
      "\u001b[?25h\u001b[33mWARNING: Connection timed out while downloading.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Attempting to resume incomplete download (9.2 MB/124.7 MB, attempt 1)\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/124.7 MB\u001b[0m \u001b[31m35.2 kB/s\u001b[0m eta \u001b[36m0:54:38\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Connection timed out while downloading.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Attempting to resume incomplete download (9.2 MB/124.7 MB, attempt 1)\u001b[0m\u001b[33m\n",
      "\u001b[0mResuming download nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.2 MB/124.7 MB)\n",
      "\u001b[?25l   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/124.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mResuming download nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.2 MB/124.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m750.4 kB/s\u001b[0m  \u001b[33m0:01:59\u001b[0m0:00:01\u001b[0m00:06\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m750.4 kB/s\u001b[0m  \u001b[33m0:01:59\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.4 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/170.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.4/170.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m  \u001b[33m0:01:28\u001b[0mm0:00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.4/170.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m  \u001b[33m0:01:28\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "\u001b[?25lInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "\u001b[2K  Attempting uninstall: triton━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/18\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Found existing installation: triton 3.1.0[0m \u001b[32m 0/18\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K  Attempting uninstall: triton━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/18\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Found existing installation: triton 3.1.0[0m \u001b[32m 0/18\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Uninstalling triton-3.1.0:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/18\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K      Successfully uninstalled triton-3.1.0━\u001b[0m \u001b[32m 0/18\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Uninstalling triton-3.1.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/18\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled triton-3.1.0━\u001b[0m \u001b[32m 0/18\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K  Attempting uninstall: sympy━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/18\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: sympy 1.13.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/18\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: sympy━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/18\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: sympy 1.13.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/18\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling sympy-1.13.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/18\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling sympy-1.13.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/18\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.13.1━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/18\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.13.1━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/18\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/18\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.1.105━━━━\u001b[0m \u001b[32m 2/18\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.1.105:━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/18\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.1.105━━━━━━\u001b[0m \u001b[32m 2/18\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/18\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.1.105━━━━\u001b[0m \u001b[32m 2/18\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.1.105:━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/18\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.1.105━━━━━━\u001b[0m \u001b[32m 2/18\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.9.86\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.9.86:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.86━━\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.9.86\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.9.86:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.86━━\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/18\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.21.5━━━━━━\u001b[0m \u001b[32m 5/18\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.21.5:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/18\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.21.5━━━━━━━━\u001b[0m \u001b[32m 5/18\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/18\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.21.5━━━━━━\u001b[0m \u001b[32m 5/18\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.21.5:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/18\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.21.5━━━━━━━━\u001b[0m \u001b[32m 5/18\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/18\u001b[0m [nvidia-nccl-cu12]]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.2.106\u001b[0m \u001b[32m 6/18\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.2.106:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/18\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.2.106━━\u001b[0m \u001b[32m 6/18\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/18\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.2.106\u001b[0m \u001b[32m 6/18\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.2.106:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/18\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.2.106━━\u001b[0m \u001b[32m 6/18\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105 \u001b[32m 8/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:━━━━━━━━━━━\u001b[0m \u001b[32m 8/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.1050m \u001b[32m 8/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105 \u001b[32m 8/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:━━━━━━━━━━━\u001b[0m \u001b[32m 8/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.1050m \u001b[32m 8/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.1050m \u001b[32m 8/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.1050m \u001b[32m 8/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\u001b[0m \u001b[32m 8/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/18\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\u001b[0m \u001b[32m 8/18\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu1290m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/18\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.1.1050m \u001b[32m10/18\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:━━━━━━━━━━━━━\u001b[0m \u001b[32m10/18\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\u001b[0m \u001b[32m10/18\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/18\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.1.1050m \u001b[32m10/18\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:━━━━━━━━━━━━━\u001b[0m \u001b[32m10/18\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\u001b[0m \u001b[32m10/18\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/18\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.1.3.1━━\u001b[0m \u001b[32m11/18\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.1.3.1:0m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/18\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/18\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.1.3.1━━\u001b[0m \u001b[32m11/18\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.1.3.1:0m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/18\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1━━━━\u001b[0m \u001b[32m11/18\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1━━━━\u001b[0m \u001b[32m11/18\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m12/18\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.1.0.1060m \u001b[32m12/18\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.1.0.106:━━━━━━━━━━━━━\u001b[0m \u001b[32m12/18\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\u001b[0m \u001b[32m12/18\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m12/18\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.1.0.1060m \u001b[32m12/18\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.1.0.106:━━━━━━━━━━━━━\u001b[0m \u001b[32m12/18\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\u001b[0m \u001b[32m12/18\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m13/18\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.0.2.54━━\u001b[0m \u001b[32m13/18\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.0.2.54:m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m13/18\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54━━━━\u001b[0m \u001b[32m13/18\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m13/18\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.0.2.54━━\u001b[0m \u001b[32m13/18\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.0.2.54:m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m13/18\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54━━━━\u001b[0m \u001b[32m13/18\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu120m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m14/18\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu1290m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m14/18\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.1.0.70━━━\u001b[0m \u001b[32m14/18\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.1.0.70:m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m15/18\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70━━━━━\u001b[0m \u001b[32m15/18\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.1.0.70━━━\u001b[0m \u001b[32m15/18\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.1.0.70:m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m15/18\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70━━━━━\u001b[0m \u001b[32m15/18\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m15/18\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.4.5.1070m \u001b[32m15/18\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.4.5.107:0m\u001b[90m━━━━━━\u001b[0m \u001b[32m15/18\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\u001b[0m \u001b[32m15/18\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m16/18\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.4.5.1070m \u001b[32m15/18\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.4.5.107:0m\u001b[90m━━━━━━\u001b[0m \u001b[32m15/18\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\u001b[0m \u001b[32m15/18\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/18\u001b[0m [torch]m17/18\u001b[0m [torch]-cusolver-cu12]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "unbabel-comet 2.2.7 requires numpy<2.0.0,>=1.20.0, but you have numpy 2.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 torch-2.9.1 triton-3.5.1\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/18\u001b[0m [torch]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "unbabel-comet 2.2.7 requires numpy<2.0.0,>=1.20.0, but you have numpy 2.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 torch-2.9.1 triton-3.5.1\n",
      "Requirement already satisfied: comet-ml in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (3.55.0)\n",
      "Requirement already satisfied: unbabel-comet in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (2.2.7)\n",
      "Requirement already satisfied: bert-score in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: sacrebleu in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (0.24.10)\n",
      "Requirement already satisfied: everett<3.2.0,>=1.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (3.1.0)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (4.25.1)\n",
      "Requirement already satisfied: psutil>=5.6.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (7.1.3)\n",
      "Requirement already satisfied: python-box<7.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (6.1.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.32.5)\n",
      "Requirement already satisfied: rich>=13.3.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (14.2.0)\n",
      "Requirement already satisfied: semantic-version>=2.8.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.10.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.1.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.47.0)\n",
      "Requirement already satisfied: simplejson in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (3.20.2)\n",
      "Requirement already satisfied: urllib3>=1.26.8 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.6.2)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.0.1)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (3.1.1)\n",
      "Requirement already satisfied: configobj in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (5.0.9)\n",
      "Requirement already satisfied: entmax<2.0,>=1.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (1.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (0.36.0)\n",
      "Requirement already satisfied: jsonargparse==3.13.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (3.13.1)\n",
      "Requirement already satisfied: comet-ml in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (3.55.0)\n",
      "Requirement already satisfied: unbabel-comet in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (2.2.7)\n",
      "Requirement already satisfied: bert-score in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: sacrebleu in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (0.24.10)\n",
      "Requirement already satisfied: everett<3.2.0,>=1.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (3.1.0)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (4.25.1)\n",
      "Requirement already satisfied: psutil>=5.6.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (7.1.3)\n",
      "Requirement already satisfied: python-box<7.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (6.1.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.32.5)\n",
      "Requirement already satisfied: rich>=13.3.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (14.2.0)\n",
      "Requirement already satisfied: semantic-version>=2.8.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.10.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.1.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.47.0)\n",
      "Requirement already satisfied: simplejson in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (3.20.2)\n",
      "Requirement already satisfied: urllib3>=1.26.8 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.6.2)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (2.0.1)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from comet-ml) (3.1.1)\n",
      "Requirement already satisfied: configobj in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (5.0.9)\n",
      "Requirement already satisfied: entmax<2.0,>=1.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (1.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (0.36.0)\n",
      "Requirement already satisfied: jsonargparse==3.13.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (3.13.1)\n",
      "Collecting numpy<2.0.0,>=1.20.0 (from unbabel-comet)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pandas>=1.4.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (2.3.3)\n",
      "Requirement already satisfied: protobuf<5.0.0,>=4.24.4 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (4.25.8)\n",
      "Requirement already satisfied: pytorch-lightning<3.0.0,>=2.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (2.6.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (1.16.3)\n",
      "Requirement already satisfied: sentencepiece<0.3.0,>=0.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (0.2.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (2.9.1)\n",
      "Requirement already satisfied: torchmetrics<0.11.0,>=0.10.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (0.10.3)\n",
      "Requirement already satisfied: transformers<5.0,>=4.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (4.46.0)\n",
      "Requirement already satisfied: PyYAML>=3.13 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jsonargparse==3.13.1->unbabel-comet) (6.0.3)\n",
      "Requirement already satisfied: portalocker in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (3.2.0)\n",
      "Requirement already satisfied: regex in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (2025.11.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (6.0.2)\n",
      "Requirement already satisfied: filelock in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (25.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (1.2.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.7.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.20.3)\n",
      "Collecting numpy<2.0.0,>=1.20.0 (from unbabel-comet)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pandas>=1.4.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (2.3.3)\n",
      "Requirement already satisfied: protobuf<5.0.0,>=4.24.4 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (4.25.8)\n",
      "Requirement already satisfied: pytorch-lightning<3.0.0,>=2.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (2.6.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (1.16.3)\n",
      "Requirement already satisfied: sentencepiece<0.3.0,>=0.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (0.2.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (2.9.1)\n",
      "Requirement already satisfied: torchmetrics<0.11.0,>=0.10.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (0.10.3)\n",
      "Requirement already satisfied: transformers<5.0,>=4.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from unbabel-comet) (4.46.0)\n",
      "Requirement already satisfied: PyYAML>=3.13 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jsonargparse==3.13.1->unbabel-comet) (6.0.3)\n",
      "Requirement already satisfied: portalocker in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (3.2.0)\n",
      "Requirement already satisfied: regex in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (2025.11.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sacrebleu) (6.0.2)\n",
      "Requirement already satisfied: filelock in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (25.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (1.2.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.7.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from bert-score) (3.10.8)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (3.13.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (3.11)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.30.0)\n",
      "Requirement already satisfied: setuptools in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (80.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas>=1.4.1->unbabel-comet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas>=1.4.1->unbabel-comet) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas>=1.4.1->unbabel-comet) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.1->unbabel-comet) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests>=2.18.4->comet-ml) (3.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests>=2.18.4->comet-ml) (2025.11.12)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from rich>=13.3.2->comet-ml) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from rich>=13.3.2->comet-ml) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet-ml) (0.1.2)\n",
      "Requirement already satisfied: matplotlib in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from bert-score) (3.10.8)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (3.13.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (3.11)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.30.0)\n",
      "Requirement already satisfied: setuptools in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (80.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas>=1.4.1->unbabel-comet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas>=1.4.1->unbabel-comet) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas>=1.4.1->unbabel-comet) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.1->unbabel-comet) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests>=2.18.4->comet-ml) (3.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests>=2.18.4->comet-ml) (2025.11.12)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from rich>=13.3.2->comet-ml) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from rich>=13.3.2->comet-ml) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet-ml) (0.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.6.0->unbabel-comet) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->unbabel-comet) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (3.2.5)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from torch>=1.6.0->unbabel-comet) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.6.0->unbabel-comet) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->unbabel-comet) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from matplotlib->bert-score) (3.2.5)\n",
      "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.5\n",
      "    Uninstalling numpy-2.3.5:\n",
      "      Successfully uninstalled numpy-2.3.5\n",
      "    Found existing installation: numpy 2.3.5\n",
      "    Uninstalling numpy-2.3.5:\n",
      "      Successfully uninstalled numpy-2.3.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "faiss-gpu-cu12 1.13.0 requires numpy<3,>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "faiss-gpu-cu12 1.13.0 requires numpy<3,>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "Requirement already satisfied: wandb in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (0.23.1)\n",
      "Requirement already satisfied: pandas in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: tqdm in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: click>=8.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (8.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (3.1.45)\n",
      "Requirement already satisfied: packaging in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (25.0)\n",
      "Requirement already satisfied: platformdirs in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (4.5.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (4.25.8)\n",
      "Requirement already satisfied: pydantic<3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (2.12.5)\n",
      "Requirement already satisfied: pyyaml in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (6.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (2.32.5)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (2.47.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pydantic<3->wandb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pydantic<3->wandb) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: wandb in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (0.23.1)\n",
      "Requirement already satisfied: pandas in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: tqdm in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: click>=8.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (8.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (3.1.45)\n",
      "Requirement already satisfied: packaging in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (25.0)\n",
      "Requirement already satisfied: platformdirs in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (4.5.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (4.25.8)\n",
      "Requirement already satisfied: pydantic<3 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (2.12.5)\n",
      "Requirement already satisfied: pyyaml in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (6.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (2.32.5)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (2.47.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from wandb) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pydantic<3->wandb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pydantic<3->wandb) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/aya/anaconda3/envs/torch_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "GPU Available: True\n",
      "Number of GPUs: 2\n",
      "  GPU 0: NVIDIA GeForce RTX 5090\n",
      "    Memory: 33.67 GB\n",
      "  GPU 1: NVIDIA GeForce RTX 5090\n",
      "    Memory: 33.67 GB\n",
      "\n",
      "Total VRAM: 67.34 GB\n",
      "Warning: Not running inside a virtual environment!\n",
      "Hugging Face token loaded from cache.\n",
      "✅ Detected project directory: .\n",
      "📁 Data directory: data\n",
      "📁 Models directory: models\n",
      "⚠️ Translation data not found at: Data/english-arabic\n",
      "✅ Directory structure and model paths are ready!\n",
      "HPC Config: 2 GPUs, Flash Attention: False\n",
      "COMET Config: model=Unbabel/wmt22-cometkiwi-da, batch_size=64, gpu=1\n",
      "✅ Configuration loaded successfully!\n",
      "   - COMET enabled for scoring\n",
      "   - LoRA enabled: True\n",
      "   - KL penalty: 0.15\n",
      "   - Sample size: 100,000\n",
      "   - Batch sizes: Generation=64, RM=16, PPO=32\n",
      "Utility functions loaded!\n",
      "Configuration saved to config.json\n",
      "GPU Available: True\n",
      "Number of GPUs: 2\n",
      "  GPU 0: NVIDIA GeForce RTX 5090\n",
      "    Memory: 33.67 GB\n",
      "  GPU 1: NVIDIA GeForce RTX 5090\n",
      "    Memory: 33.67 GB\n",
      "\n",
      "Total VRAM: 67.34 GB\n",
      "Warning: Not running inside a virtual environment!\n",
      "Hugging Face token loaded from cache.\n",
      "✅ Detected project directory: .\n",
      "📁 Data directory: data\n",
      "📁 Models directory: models\n",
      "⚠️ Translation data not found at: Data/english-arabic\n",
      "✅ Directory structure and model paths are ready!\n",
      "HPC Config: 2 GPUs, Flash Attention: False\n",
      "COMET Config: model=Unbabel/wmt22-cometkiwi-da, batch_size=64, gpu=1\n",
      "✅ Configuration loaded successfully!\n",
      "   - COMET enabled for scoring\n",
      "   - LoRA enabled: True\n",
      "   - KL penalty: 0.15\n",
      "   - Sample size: 100,000\n",
      "   - Batch sizes: Generation=64, RM=16, PPO=32\n",
      "Utility functions loaded!\n",
      "Configuration saved to config.json\n"
     ]
    }
   ],
   "source": [
    "# Run setup from config notebook\n",
    "%run 0_config_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2ea6ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Reward Model Training - HPC Optimized\n",
      "   Batch size: 16\n",
      "   Learning rate: 1.5e-05\n",
      "   Epochs: 3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, get_scheduler\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import wandb\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "import random\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "print(\"🚀 Reward Model Training - HPC Optimized\")\n",
    "print(f\"   Batch size: {RM_BATCH_SIZE}\")\n",
    "print(f\"   Learning rate: {RM_LEARNING_RATE}\")\n",
    "print(f\"   Epochs: {RM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9713d8eb",
   "metadata": {},
   "source": [
    "## Load Synthetic Preference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2165021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading synthetic preference data...\n",
      "  EN: outputs/en-ar-preferences.jsonl\n",
      "  FR: outputs/fr-ar-preferences.jsonl\n",
      "✓ Loaded 44324 English preference pairs\n",
      "✓ Loaded 46908 French preference pairs\n",
      "\n",
      "Total preference pairs (EN + FR): 91232\n",
      "Train: 82108 pairs\n",
      "Validation: 9124 pairs\n",
      "\n",
      "Language breakdown (train):\n",
      "  English: 44324 (54.0%)\n",
      "  French: 37784 (46.0%)\n",
      "\n",
      "Language breakdown (validation):\n",
      "  English: 0 (0.0%)\n",
      "  French: 9124 (100.0%)\n",
      "✓ Loaded 46908 French preference pairs\n",
      "\n",
      "Total preference pairs (EN + FR): 91232\n",
      "Train: 82108 pairs\n",
      "Validation: 9124 pairs\n",
      "\n",
      "Language breakdown (train):\n",
      "  English: 44324 (54.0%)\n",
      "  French: 37784 (46.0%)\n",
      "\n",
      "Language breakdown (validation):\n",
      "  English: 0 (0.0%)\n",
      "  French: 9124 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Load English and French preference files\n",
    "print(\"Loading synthetic preference data...\")\n",
    "print(f\"  EN: {OUTPUTS_DIR / 'en-ar-preferences.jsonl'}\")\n",
    "print(f\"  FR: {OUTPUTS_DIR / 'fr-ar-preferences.jsonl'}\")\n",
    "\n",
    "preference_data = []\n",
    "\n",
    "# Load English preferences\n",
    "en_pref_file = OUTPUTS_DIR / \"en-ar-preferences.jsonl\"\n",
    "if en_pref_file.exists():\n",
    "    with open(en_pref_file, 'r', encoding='utf-8') as f:\n",
    "        en_count = 0\n",
    "        for line in f:\n",
    "            preference_data.append(json.loads(line))\n",
    "            en_count += 1\n",
    "    print(f\"✓ Loaded {en_count} English preference pairs\")\n",
    "else:\n",
    "    print(f\"⚠️  EN preferences file not found: {en_pref_file}\")\n",
    "\n",
    "# Load French preferences\n",
    "fr_pref_file = OUTPUTS_DIR / \"fr-ar-preferences.jsonl\"\n",
    "if fr_pref_file.exists():\n",
    "    with open(fr_pref_file, 'r', encoding='utf-8') as f:\n",
    "        fr_count = 0\n",
    "        for line in f:\n",
    "            preference_data.append(json.loads(line))\n",
    "            fr_count += 1\n",
    "    print(f\"✓ Loaded {fr_count} French preference pairs\")\n",
    "else:\n",
    "    print(f\"⚠️  FR preferences file not found: {fr_pref_file}\")\n",
    "\n",
    "print(f\"\\nTotal preference pairs (EN + FR): {len(preference_data)}\")\n",
    "\n",
    "if len(preference_data) == 0:\n",
    "    raise ValueError(\"No preference data loaded! Check file paths.\")\n",
    "\n",
    "# Split into train/validation (mixed batches from both languages)\n",
    "train_size = int(0.9 * len(preference_data))\n",
    "train_data = preference_data[:train_size]\n",
    "val_data = preference_data[train_size:]\n",
    "\n",
    "print(f\"Train: {len(train_data)} pairs\")\n",
    "print(f\"Validation: {len(val_data)} pairs\")\n",
    "\n",
    "# Language breakdown\n",
    "en_train = sum(1 for item in train_data if item.get('source_lang') == 'en')\n",
    "fr_train = sum(1 for item in train_data if item.get('source_lang') == 'fr')\n",
    "en_val = sum(1 for item in val_data if item.get('source_lang') == 'en')\n",
    "fr_val = sum(1 for item in val_data if item.get('source_lang') == 'fr')\n",
    "\n",
    "print(f\"\\nLanguage breakdown (train):\")\n",
    "print(f\"  English: {en_train} ({100*en_train/len(train_data):.1f}%)\")\n",
    "print(f\"  French: {fr_train} ({100*fr_train/len(train_data):.1f}%)\")\n",
    "print(f\"\\nLanguage breakdown (validation):\")\n",
    "print(f\"  English: {en_val} ({100*en_val/len(val_data):.1f}%)\")\n",
    "print(f\"  French: {fr_val} ({100*fr_val/len(val_data):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b91a6072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating preference data quality...\n",
      "Margin statistics (all 91232 samples):\n",
      "  Min: 0.0100\n",
      "  Max: 0.7900\n",
      "  Mean: 0.0633\n",
      "  Std: 0.0505\n",
      "  Samples with margin < 0.01: 0/91232\n",
      "\n",
      "English margin stats (n=44324): mean=0.0549\n",
      "French margin stats (n=46908): mean=0.0712\n"
     ]
    }
   ],
   "source": [
    "# Validate preference data quality\n",
    "print(\"\\nValidating preference data quality...\")\n",
    "sample_margins = [item['margin'] for item in preference_data]\n",
    "print(f\"Margin statistics (all {len(sample_margins)} samples):\")\n",
    "print(f\"  Min: {min(sample_margins):.4f}\")\n",
    "print(f\"  Max: {max(sample_margins):.4f}\")\n",
    "mean_margin = sum(sample_margins)/len(sample_margins)\n",
    "print(f\"  Mean: {mean_margin:.4f}\")\n",
    "if len(sample_margins) > 1:\n",
    "    std_margin = (sum((x - mean_margin)**2 for x in sample_margins)/len(sample_margins))**0.5\n",
    "    print(f\"  Std: {std_margin:.4f}\")\n",
    "\n",
    "# Check for degenerate cases\n",
    "zero_margin_count = sum(1 for item in preference_data if item['margin'] < 0.01)\n",
    "print(f\"  Samples with margin < 0.01: {zero_margin_count}/{len(preference_data)}\")\n",
    "if zero_margin_count > len(preference_data) * 0.5:\n",
    "    print(\"  ⚠️  WARNING: >50% of samples have near-zero margins (weak preference signal)\")\n",
    "\n",
    "# Quality by language\n",
    "if any('source_lang' in item for item in preference_data):\n",
    "    en_margins = [item['margin'] for item in preference_data if item.get('source_lang') == 'en']\n",
    "    fr_margins = [item['margin'] for item in preference_data if item.get('source_lang') == 'fr']\n",
    "    \n",
    "    if en_margins:\n",
    "        en_mean = sum(en_margins)/len(en_margins)\n",
    "        print(f\"\\nEnglish margin stats (n={len(en_margins)}): mean={en_mean:.4f}\")\n",
    "    if fr_margins:\n",
    "        fr_mean = sum(fr_margins)/len(fr_margins)\n",
    "        print(f\"French margin stats (n={len(fr_margins)}): mean={fr_mean:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7732aa83",
   "metadata": {},
   "source": [
    "## Preference Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "075da4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreferenceDataset class defined (max_length=512)\n"
     ]
    }
   ],
   "source": [
    "class PreferenceDataset(Dataset):\n",
    "    \"\"\"Dataset for pairwise preference data\"\"\"\n",
    "    \n",
    "    def __init__(self, data, tokenizer, max_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        # Format: \"Source: ... \\nTranslation: ...\"\n",
    "        chosen_text = f\"Source: {item['source']}\\nTranslation: {item['chosen']}\"\n",
    "        rejected_text = f\"Source: {item['source']}\\nTranslation: {item['rejected']}\"\n",
    "        \n",
    "        # Tokenize\n",
    "        chosen_tokens = self.tokenizer(\n",
    "            chosen_text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        rejected_tokens = self.tokenizer(\n",
    "            rejected_text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'chosen_input_ids': chosen_tokens['input_ids'].squeeze(0),\n",
    "            'chosen_attention_mask': chosen_tokens['attention_mask'].squeeze(0),\n",
    "            'rejected_input_ids': rejected_tokens['input_ids'].squeeze(0),\n",
    "            'rejected_attention_mask': rejected_tokens['attention_mask'].squeeze(0),\n",
    "            'margin': item['margin']  # For analysis\n",
    "        }\n",
    "\n",
    "print(\"PreferenceDataset class defined (max_length=512)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae73ece",
   "metadata": {},
   "source": [
    "## Reward Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caa918a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RewardModel class defined\n"
     ]
    }
   ],
   "source": [
    "class RewardModel(nn.Module):\n",
    "    \"\"\"Reward model with base LM + reward head\"\"\"\n",
    "    \n",
    "    def __init__(self, base_model, hidden_dim=256, head_type='mlp', dropout=0.15):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.head_type = head_type\n",
    "        \n",
    "        # Get hidden size from base model\n",
    "        self.hidden_size = base_model.config.hidden_size\n",
    "        \n",
    "        # Reward head\n",
    "        if head_type == 'linear':\n",
    "            self.reward_head = nn.Linear(self.hidden_size, 1)\n",
    "        elif head_type == 'mlp':\n",
    "            self.reward_head = nn.Sequential(\n",
    "                nn.Linear(self.hidden_size, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(hidden_dim, 1)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown head_type: {head_type}\")\n",
    "        \n",
    "        # Initialize reward head with larger output scale\n",
    "        with torch.no_grad():\n",
    "            if head_type == 'mlp':\n",
    "                # Scale final layer to produce larger reward values\n",
    "                self.reward_head[-1].weight.mul_(2.0)\n",
    "                self.reward_head[-1].bias.mul_(2.0)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get base model outputs with hidden states\n",
    "        outputs = self.base_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,  # Need hidden states for reward computation\n",
    "            use_cache=False  # Disable cache to avoid device placement issues with multi-GPU\n",
    "        )\n",
    "        \n",
    "        # Get last hidden state from hidden_states tuple\n",
    "        # hidden_states is a tuple of all layer outputs, last one is what we need\n",
    "        hidden_states = outputs.hidden_states[-1]  # [batch, seq_len, hidden_size]\n",
    "        \n",
    "        # Pool: use last token representation (similar to value head in PPO)\n",
    "        # Get the last non-padding token for each sequence\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = hidden_states.shape[0]\n",
    "        pooled = hidden_states[torch.arange(batch_size), sequence_lengths]\n",
    "        \n",
    "        # Apply reward head\n",
    "        reward = self.reward_head(pooled)  # [batch, 1]\n",
    "        \n",
    "        return reward.squeeze(-1)  # [batch]\n",
    "\n",
    "print(\"RewardModel class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da92850",
   "metadata": {},
   "source": [
    "## Load Base Model and Create Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86a4891f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model: google/gemma-2-2b...\n",
      "🚀 HPC Optimized loading\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619cf32be11d47deb1ea7bc58d925819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /google/gemma-2-2b/resolve/main/tokenizer_config.json (Caused by NameResolutionError(\"HTTPSConnection(host=\\'huggingface.co\\', port=443): Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: 517afb80-6709-4bb9-a4bd-1eb6ddab2c1f)')' thrown while requesting HEAD https://huggingface.co/google/gemma-2-2b/resolve/main/tokenizer_config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ HuggingFace authenticated\n",
      "✓ Using both GPUs (auto device mapping)\n",
      "✓ Using both GPUs (auto device mapping)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad4b18f3b6f4e40bb9c1dd87f356112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Base model loaded (unfrozen last 6 layers)\n",
      "✓ Gradient checkpointing disabled (maximum speed with dual GPUs)\n",
      "✓ Reward model created with mlp head\n",
      "Total parameters: 2614.93M\n",
      "Trainable parameters: 467.79M\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading base model: {REWARD_BASE_MODEL}...\")\n",
    "print(\"🚀 HPC Optimized loading\\n\")\n",
    "\n",
    "# Ensure HF authentication\n",
    "from huggingface_hub import login\n",
    "try:\n",
    "    # Try to login with cached token\n",
    "    login()\n",
    "    print(\"✓ HuggingFace authenticated\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ HuggingFace auth warning: {e}\")\n",
    "    print(\"If this fails, run: huggingface-cli login\")\n",
    "\n",
    "# Load tokenizer\n",
    "rm_tokenizer = AutoTokenizer.from_pretrained(REWARD_BASE_MODEL, trust_remote_code=True)\n",
    "if rm_tokenizer.pad_token is None:\n",
    "    rm_tokenizer.pad_token = rm_tokenizer.eos_token\n",
    "\n",
    "# Load base model with HPC optimizations - using both GPUs\n",
    "model_kwargs = {\n",
    "    \"torch_dtype\": torch.bfloat16,\n",
    "    \"device_map\": \"auto\",  # Auto-distribute across both GPUs\n",
    "    \"trust_remote_code\": True,\n",
    "    \"low_cpu_mem_usage\": True,  # Memory efficient loading\n",
    "}\n",
    "\n",
    "# Add Flash Attention if available\n",
    "if USE_FLASH_ATTENTION:\n",
    "    model_kwargs[\"attn_implementation\"] = ATTN_IMPLEMENTATION\n",
    "    print(\"✓ Flash Attention 2 enabled\")\n",
    "\n",
    "print(f\"✓ Using both GPUs (auto device mapping)\")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(REWARD_BASE_MODEL, **model_kwargs)\n",
    "\n",
    "# Gradient checkpointing disabled for maximum speed with dual GPUs\n",
    "# (Both 31GB GPUs have sufficient memory for batch_size=8 without checkpointing)\n",
    "# base_model.gradient_checkpointing_enable()  # Uncomment if running out of memory\n",
    "\n",
    "# Freeze base model parameters (fine-tune only last layers)\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze last few layers for fine-tuning\n",
    "num_unfrozen_layers = RM_UNFROZEN_LAYERS  # From config (6 layers for single GPU)\n",
    "for layer in base_model.model.layers[-num_unfrozen_layers:]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "print(f\"✓ Base model loaded (unfrozen last {num_unfrozen_layers} layers)\")\n",
    "print(f\"✓ Gradient checkpointing disabled (maximum speed with dual GPUs)\")\n",
    "\n",
    "# Create reward model with dropout regularization\n",
    "reward_model = RewardModel(\n",
    "    base_model=base_model,\n",
    "    hidden_dim=RM_HIDDEN_DIM,\n",
    "    head_type=RM_HEAD_TYPE,\n",
    "    dropout=RM_DROPOUT  # Use configured dropout for regularization\n",
    ")\n",
    "\n",
    "# Move reward head to cuda:0 and convert to bfloat16 to match base model dtype\n",
    "reward_model.reward_head = reward_model.reward_head.to('cuda:0').to(torch.bfloat16)\n",
    "\n",
    "print(f\"✓ Reward model created with {RM_HEAD_TYPE} head\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in reward_model.parameters()) / 1e6:.2f}M\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in reward_model.parameters() if p.requires_grad) / 1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8dee49",
   "metadata": {},
   "source": [
    "## Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7e66565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 5132\n",
      "Validation batches: 571\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = PreferenceDataset(train_data, rm_tokenizer, max_length=RM_MAX_LENGTH)\n",
    "val_dataset = PreferenceDataset(val_data, rm_tokenizer, max_length=RM_MAX_LENGTH)\n",
    "\n",
    "# Create dataloaders with HPC optimized settings\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=RM_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,  # Parallel data loading for HPC\n",
    "    pin_memory=True,  # Faster GPU transfer\n",
    "    prefetch_factor=2  # Prefetch batches\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=RM_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c33872cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Device Configuration:\n",
      "Number of GPUs available: 2\n",
      "GPU 0: NVIDIA GeForce RTX 5090\n",
      "GPU 1: NVIDIA GeForce RTX 5090\n",
      "\n",
      "Model placement (distributed across both GPUs):\n",
      "\n",
      "✓ GPU 0 (cuda:0):\n",
      "  - Parameters: 1291.21M (49.4%)\n",
      "  - Unique layers: 3\n",
      "\n",
      "✓ GPU 1 (cuda:1):\n",
      "  - Parameters: 1323.72M (50.6%)\n",
      "  - Unique layers: 1\n",
      "\n",
      "✓ Model IS using both GPUs (auto device map)\n",
      "\n",
      "Sample layers on GPU 0: ['base_model.model', 'reward_head.0', 'reward_head.3']\n",
      "Sample layers on GPU 1: ['base_model.model']\n"
     ]
    }
   ],
   "source": [
    "# Check GPU device configuration\n",
    "print(\"GPU Device Configuration:\")\n",
    "print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "print(\"\\nModel placement (distributed across both GPUs):\")\n",
    "\n",
    "# Count parameters per device\n",
    "device_0_params = 0\n",
    "device_1_params = 0\n",
    "device_0_layers = []\n",
    "device_1_layers = []\n",
    "\n",
    "for name, param in reward_model.named_parameters():\n",
    "    param_size = param.numel()\n",
    "    if 'cuda:0' in str(param.device):\n",
    "        device_0_params += param_size\n",
    "        # Track which layers are on cuda:0\n",
    "        layer_name = name.split('.')[0:2]\n",
    "        layer_name = '.'.join(layer_name)\n",
    "        if layer_name not in device_0_layers:\n",
    "            device_0_layers.append(layer_name)\n",
    "    elif 'cuda:1' in str(param.device):\n",
    "        device_1_params += param_size\n",
    "        # Track which layers are on cuda:1\n",
    "        layer_name = name.split('.')[0:2]\n",
    "        layer_name = '.'.join(layer_name)\n",
    "        if layer_name not in device_1_layers:\n",
    "            device_1_layers.append(layer_name)\n",
    "\n",
    "total_params = device_0_params + device_1_params\n",
    "\n",
    "print(f\"\\n✓ GPU 0 (cuda:0):\")\n",
    "print(f\"  - Parameters: {device_0_params/1e6:.2f}M ({100*device_0_params/total_params:.1f}%)\")\n",
    "print(f\"  - Unique layers: {len(device_0_layers)}\")\n",
    "\n",
    "print(f\"\\n✓ GPU 1 (cuda:1):\")\n",
    "print(f\"  - Parameters: {device_1_params/1e6:.2f}M ({100*device_1_params/total_params:.1f}%)\")\n",
    "print(f\"  - Unique layers: {len(device_1_layers)}\")\n",
    "\n",
    "print(f\"\\n✓ Model IS using both GPUs (auto device map)\")\n",
    "\n",
    "# Show sample of layers on each GPU\n",
    "if device_0_layers:\n",
    "    print(f\"\\nSample layers on GPU 0: {device_0_layers[:3]}\")\n",
    "if device_1_layers:\n",
    "    print(f\"Sample layers on GPU 1: {device_1_layers[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665ba7c7",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9874cc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ W&B disabled (set USE_WANDB=True to enable)\n",
      "Training setup complete!\n",
      "Total training steps: 7698\n",
      "\n",
      "Training on BOTH English and French preferences jointly\n",
      "  Train: 82108 pairs (EN + FR mixed)\n",
      "  Val: 9124 pairs (EN + FR mixed)\n"
     ]
    }
   ],
   "source": [
    "# Bradley-Terry loss with margin for pairwise preferences\n",
    "def bradley_terry_loss(chosen_rewards, rejected_rewards, margin=0.5):\n",
    "    \"\"\"\n",
    "    Bradley-Terry model loss with margin: -log(sigmoid(r_chosen - r_rejected - margin))\n",
    "    \n",
    "    The model learns to make r_chosen > r_rejected by at least 'margin'.\n",
    "    This encourages stronger preference differentiation.\n",
    "    \"\"\"\n",
    "    # Compute difference with margin requirement\n",
    "    diff = chosen_rewards - rejected_rewards - margin\n",
    "    \n",
    "    # Add numerical stability with clipping\n",
    "    diff = torch.clamp(diff, min=-10, max=10)\n",
    "    \n",
    "    # Loss: -log(sigmoid(diff))\n",
    "    # This is minimized when diff → ∞ (chosen >> rejected by margin)\n",
    "    loss = -torch.log(torch.sigmoid(diff) + 1e-8)\n",
    "    return loss.mean()\n",
    "\n",
    "# Get trainable parameters\n",
    "trainable_params = [p for p in reward_model.parameters() if p.requires_grad]\n",
    "\n",
    "# Optimizer with weight decay for regularization\n",
    "optimizer = torch.optim.AdamW(\n",
    "    trainable_params,\n",
    "    lr=RM_LEARNING_RATE,\n",
    "    weight_decay=RM_WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "num_training_steps = len(train_loader) * RM_EPOCHS // RM_GRADIENT_ACCUMULATION_STEPS\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"cosine\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=num_training_steps // 10,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Initialize wandb (optional) - disabled by default\n",
    "if USE_WANDB:\n",
    "    import os\n",
    "    os.environ['WANDB_MODE'] = 'online'\n",
    "    wandb.init(\n",
    "        project=WANDB_PROJECT,\n",
    "        name=\"reward-model-coldstart\",\n",
    "        config={\n",
    "            'learning_rate': RM_LEARNING_RATE,\n",
    "            'batch_size': RM_BATCH_SIZE,\n",
    "            'epochs': RM_EPOCHS,\n",
    "            'base_model': REWARD_BASE_MODEL,\n",
    "            'head_type': RM_HEAD_TYPE,\n",
    "            'num_gpus': NUM_GPUS\n",
    "        }\n",
    "    )\n",
    "    print(\"✓ W&B initialized\")\n",
    "else:\n",
    "    print(\"✓ W&B disabled (set USE_WANDB=True to enable)\")\n",
    "\n",
    "print(\"Training setup complete!\")\n",
    "print(f\"Total training steps: {num_training_steps}\")\n",
    "print(f\"\\nTraining on BOTH English and French preferences jointly\")\n",
    "print(f\"  Train: {len(train_data)} pairs (EN + FR mixed)\")\n",
    "print(f\"  Val: {len(val_data)} pairs (EN + FR mixed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71beaf2e",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ebc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, loader, optimizer, scheduler, device, gradient_accumulation_steps=1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Training\")\n",
    "    for step, batch in enumerate(pbar):\n",
    "        # Move to device\n",
    "        chosen_input_ids = batch['chosen_input_ids'].to(device)\n",
    "        chosen_attention_mask = batch['chosen_attention_mask'].to(device)\n",
    "        rejected_input_ids = batch['rejected_input_ids'].to(device)\n",
    "        rejected_attention_mask = batch['rejected_attention_mask'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        chosen_rewards = model(chosen_input_ids, chosen_attention_mask)\n",
    "        rejected_rewards = model(rejected_input_ids, rejected_attention_mask)\n",
    "        \n",
    "        # DEBUG: Check reward values (first batch only) - convert to float32 for printing\n",
    "        if step == 0:\n",
    "            print(f\"\\n[DEBUG] Batch 0 - First 5 samples:\")\n",
    "            print(f\"  Chosen rewards: {chosen_rewards[:5].float().detach().cpu().numpy()}\")\n",
    "            print(f\"  Rejected rewards: {rejected_rewards[:5].float().detach().cpu().numpy()}\")\n",
    "            print(f\"  Difference (should be > 0.5): {(chosen_rewards - rejected_rewards)[:5].float().detach().cpu().numpy()}\")\n",
    "        \n",
    "        # Compute loss with margin to enforce strong preference differentiation\n",
    "        loss = bradley_terry_loss(chosen_rewards, rejected_rewards, margin=0.5)\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Accuracy: chosen should have higher reward (no margin for accuracy, just basic preference)\n",
    "        accuracy = (chosen_rewards > rejected_rewards).float().mean()\n",
    "        \n",
    "        total_loss += loss.item() * gradient_accumulation_steps\n",
    "        total_accuracy += accuracy.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update weights\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f\"{total_loss / num_batches:.4f}\",\n",
    "            'acc': f\"{total_accuracy / num_batches:.4f}\",\n",
    "            'lr': f\"{scheduler.get_last_lr()[0]:.2e}\"\n",
    "        })\n",
    "    \n",
    "    return total_loss / num_batches, total_accuracy / num_batches\n",
    "\n",
    "\n",
    "def validate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Validation\"):\n",
    "            chosen_input_ids = batch['chosen_input_ids'].to(device)\n",
    "            chosen_attention_mask = batch['chosen_attention_mask'].to(device)\n",
    "            rejected_input_ids = batch['rejected_input_ids'].to(device)\n",
    "            rejected_attention_mask = batch['rejected_attention_mask'].to(device)\n",
    "            \n",
    "            chosen_rewards = model(chosen_input_ids, chosen_attention_mask)\n",
    "            rejected_rewards = model(rejected_input_ids, rejected_attention_mask)\n",
    "            \n",
    "            # Use margin=0.5 in validation too for consistency\n",
    "            loss = bradley_terry_loss(chosen_rewards, rejected_rewards, margin=0.5)\n",
    "            accuracy = (chosen_rewards > rejected_rewards).float().mean()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_accuracy += accuracy.item()\n",
    "            num_batches += 1\n",
    "    \n",
    "    return total_loss / num_batches, total_accuracy / num_batches\n",
    "\n",
    "print(\"Training functions defined (with margin-based Bradley-Terry loss)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce2f1cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SANITY CHECK - Pre-Training (Random Initialization Expected)\n",
      "================================================================================\n",
      "\n",
      "Reward Model Output (Untrained - Random Init):\n",
      "  Chosen reward: 0.7383\n",
      "  Rejected reward: 0.7383\n",
      "  Difference: 0.0000\n",
      "  Currently correct? False\n",
      "\n",
      "⚠️  NOTE: Rewards are similar because model is randomly initialized.\n",
      "           Training will learn to differentiate chosen vs rejected.\n",
      "\n",
      "Data Validation:\n",
      "  Margin (expected difference): 0.1667\n",
      "  Data is ready for training ✓\n",
      "================================================================================\n",
      "\n",
      "Reward Model Output (Untrained - Random Init):\n",
      "  Chosen reward: 0.7383\n",
      "  Rejected reward: 0.7383\n",
      "  Difference: 0.0000\n",
      "  Currently correct? False\n",
      "\n",
      "⚠️  NOTE: Rewards are similar because model is randomly initialized.\n",
      "           Training will learn to differentiate chosen vs rejected.\n",
      "\n",
      "Data Validation:\n",
      "  Margin (expected difference): 0.1667\n",
      "  Data is ready for training ✓\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define device for sanity check\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Quick sanity check - BEFORE training (random initialization expected)\n",
    "print(\"=\" * 80)\n",
    "print(\"SANITY CHECK - Pre-Training (Random Initialization Expected)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "reward_model.eval()\n",
    "with torch.no_grad():\n",
    "    # Test on first batch\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    chosen_ids = sample_batch['chosen_input_ids'][:1].to(device)\n",
    "    chosen_mask = sample_batch['chosen_attention_mask'][:1].to(device)\n",
    "    rejected_ids = sample_batch['rejected_input_ids'][:1].to(device)\n",
    "    rejected_mask = sample_batch['rejected_attention_mask'][:1].to(device)\n",
    "    \n",
    "    r_chosen = reward_model(chosen_ids, chosen_mask).item()\n",
    "    r_rejected = reward_model(rejected_ids, rejected_mask).item()\n",
    "    \n",
    "    print(f\"\\nReward Model Output (Untrained - Random Init):\")\n",
    "    print(f\"  Chosen reward: {r_chosen:.4f}\")\n",
    "    print(f\"  Rejected reward: {r_rejected:.4f}\")\n",
    "    print(f\"  Difference: {r_chosen - r_rejected:.4f}\")\n",
    "    print(f\"  Currently correct? {r_chosen > r_rejected}\")\n",
    "    \n",
    "    print(f\"\\n⚠️  NOTE: Rewards are similar because model is randomly initialized.\")\n",
    "    print(f\"           Training will learn to differentiate chosen vs rejected.\")\n",
    "    \n",
    "    # Check data\n",
    "    print(f\"\\nData Validation:\")\n",
    "    print(f\"  Margin (expected difference): {sample_batch['margin'][0]:.4f}\")\n",
    "    print(f\"  Data is ready for training ✓\")\n",
    "    \n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b5effa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA QUALITY CHECK - Preference Label Consistency\n",
      "================================================================================\n",
      "\n",
      "Sample consistency check (first 1000 samples):\n",
      "  Inconsistent labels: 0/1000 (0.0%)\n",
      "\n",
      "✓ All labels are consistent (chosen > rejected)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Check for label consistency in preference data\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA QUALITY CHECK - Preference Label Consistency\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "inconsistent_count = 0\n",
    "for i, item in enumerate(preference_data[:1000]):  # Check first 1000 samples\n",
    "    # Check if chosen_score > rejected_score (should be true for valid preferences)\n",
    "    if item['chosen_score'] <= item['rejected_score']:\n",
    "        inconsistent_count += 1\n",
    "        if inconsistent_count <= 5:  # Show first 5 examples\n",
    "            print(f\"\\n⚠️  Sample {i}: INCONSISTENT LABEL\")\n",
    "            print(f\"   Chosen score:   {item['chosen_score']:.4f}\")\n",
    "            print(f\"   Rejected score: {item['rejected_score']:.4f}\")\n",
    "            print(f\"   Margin:         {item['margin']:.4f} (should be > 0)\")\n",
    "\n",
    "print(f\"\\nSample consistency check (first 1000 samples):\")\n",
    "print(f\"  Inconsistent labels: {inconsistent_count}/1000 ({100*inconsistent_count/1000:.1f}%)\")\n",
    "\n",
    "if inconsistent_count > 100:\n",
    "    print(f\"\\n🔴 CRITICAL: {inconsistent_count/10:.1f}% of data has inverted labels!\")\n",
    "    print(f\"   The chosen translations have LOWER scores than rejected ones.\")\n",
    "    print(f\"   This will prevent the reward model from learning properly.\")\n",
    "    print(f\"\\n   Fix: Re-run notebook 1 (synthetic_data_generation.ipynb)\")\n",
    "    print(f\"   Make sure preference generation correctly identifies better translations.\")\n",
    "elif inconsistent_count > 0:\n",
    "    print(f\"\\n🟡 WARNING: {100*inconsistent_count/1000:.1f}% of samples have inverted labels\")\n",
    "    print(f\"   This is acceptable but may impact convergence.\")\n",
    "else:\n",
    "    print(f\"\\n✓ All labels are consistent (chosen > rejected)\")\n",
    "\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5babaec2",
   "metadata": {},
   "source": [
    "## ⚠️ CRITICAL FIX: Validation Accuracy Issue\n",
    "\n",
    "**Problem Identified:**\n",
    "- Validation accuracy: 0.0028 (essentially 0%)\n",
    "- Training accuracy: ~0.40\n",
    "- This indicates the validation function has a device mismatch with multi-GPU setup\n",
    "\n",
    "**Root Causes:**\n",
    "1. Reward head on cuda:0 but hidden states distributed across both GPUs → device mismatch\n",
    "2. Reward values too small (~0.048) to drive learning in Bradley-Terry loss\n",
    "\n",
    "**Applied Fixes:**\n",
    "1. ✅ Removed manual device placement in validate() function (was forcing cuda:0, breaks auto device mapping)\n",
    "2. ✅ Added initialization scaling to RewardModel (multiply final layer by 2.0)\n",
    "3. ✅ Ensure validation runs with proper device handling\n",
    "\n",
    "**Action:** Re-run training from cell below with fixed code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ee3fb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RESTARTING TRAINING WITH FIXED VALIDATION\n",
      "================================================================================\n",
      "\n",
      "✓ Cleared GPU memory\n",
      "\n",
      "Reloading base model: google/gemma-2-2b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "045177d175844d0cae650442bf3f2449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Base model reloaded (unfrozen last 6 layers)\n",
      "✓ Reward model reloaded with fixed initialization\n",
      "  - Reward head scaling: 2.0x (for better learning signal)\n",
      "✓ Optimizer and scheduler recreated\n",
      "\n",
      "✅ Ready to restart training with fixes!\n"
     ]
    }
   ],
   "source": [
    "# RESTART TRAINING - Reload model with fixes\n",
    "import time\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RESTARTING TRAINING WITH FIXED VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Clear any previous model state\n",
    "del reward_model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n✓ Cleared GPU memory\\n\")\n",
    "\n",
    "# Reload base model with HPC optimizations\n",
    "print(f\"Reloading base model: {REWARD_BASE_MODEL}...\")\n",
    "\n",
    "# Define model kwargs (same as before)\n",
    "model_kwargs = {\n",
    "    \"torch_dtype\": torch.bfloat16,\n",
    "    \"device_map\": \"auto\",\n",
    "    \"trust_remote_code\": True,\n",
    "    \"low_cpu_mem_usage\": True,\n",
    "}\n",
    "\n",
    "if USE_FLASH_ATTENTION:\n",
    "    model_kwargs[\"attn_implementation\"] = ATTN_IMPLEMENTATION\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(REWARD_BASE_MODEL, **model_kwargs)\n",
    "\n",
    "# Freeze base model parameters\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze last few layers\n",
    "num_unfrozen_layers = RM_UNFROZEN_LAYERS\n",
    "for layer in base_model.model.layers[-num_unfrozen_layers:]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "print(f\"✓ Base model reloaded (unfrozen last {num_unfrozen_layers} layers)\")\n",
    "\n",
    "# Create NEW reward model with fixed initialization\n",
    "reward_model = RewardModel(\n",
    "    base_model=base_model,\n",
    "    hidden_dim=RM_HIDDEN_DIM,\n",
    "    head_type=RM_HEAD_TYPE,\n",
    "    dropout=RM_DROPOUT\n",
    ")\n",
    "\n",
    "# Move reward head to cuda:0 and convert to bfloat16\n",
    "reward_model.reward_head = reward_model.reward_head.to('cuda:0').to(torch.bfloat16)\n",
    "\n",
    "print(f\"✓ Reward model reloaded with fixed initialization\")\n",
    "print(f\"  - Reward head scaling: 2.0x (for better learning signal)\")\n",
    "\n",
    "# Recreate optimizer and scheduler\n",
    "trainable_params = [p for p in reward_model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.AdamW(\n",
    "    trainable_params,\n",
    "    lr=RM_LEARNING_RATE,\n",
    "    weight_decay=RM_WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "num_training_steps = len(train_loader) * RM_EPOCHS // RM_GRADIENT_ACCUMULATION_STEPS\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"cosine\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=num_training_steps // 10,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "print(f\"✓ Optimizer and scheduler recreated\")\n",
    "print(f\"\\n✅ Ready to restart training with fixes!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c41f3b",
   "metadata": {},
   "source": [
    "## ✅ CRITICAL FIX: Margin-Based Bradley-Terry Loss\n",
    "\n",
    "**Problem with Previous Run:**\n",
    "- Rewards ARE properly scaled (values like 1.73, -0.52, not tiny -0.048)\n",
    "- BUT: Model not learning preference differentiation \n",
    "- Only 3/5 samples showed chosen > rejected preference in first batch\n",
    "- Loss function wasn't strong enough to push apart chosen vs rejected\n",
    "\n",
    "**Solution Applied:**\n",
    "1. ✅ Updated `bradley_terry_loss()` with margin parameter\n",
    "2. ✅ Changed from: `-log(sigmoid(r_chosen - r_rejected))`\n",
    "3. ✅ Changed to: `-log(sigmoid(r_chosen - r_rejected - 0.5))`\n",
    "4. ✅ Margin = 0.5 means model must make chosen ≥ 0.5 higher than rejected\n",
    "5. ✅ Updated both train and validation functions to use margin\n",
    "\n",
    "**Why This Works:**\n",
    "- Original loss only required chosen > rejected (even by 0.01)\n",
    "- New loss with margin=0.5 requires a meaningful 0.5-point gap\n",
    "- Forces the model to learn strong discriminative preference\n",
    "- Prevents weak, ambiguous preferences\n",
    "\n",
    "**Action:**\n",
    "Continue training from the next cell - it will use the updated loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c33e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESTART TRAINING WITH MARGIN-BASED LOSS\n",
    "# Clear GPU memory and reload model fresh\n",
    "torch.cuda.empty_cache()\n",
    "print(\"=\" * 80)\n",
    "print(\"RESTARTING TRAINING WITH MARGIN-BASED BRADLEY-TERRY LOSS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Reload base model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(REWARD_BASE_MODEL, **model_kwargs)\n",
    "\n",
    "# Freeze and unfreeze layers\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for layer in base_model.model.layers[-RM_UNFROZEN_LAYERS:]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Create new reward model\n",
    "reward_model = RewardModel(\n",
    "    base_model=base_model,\n",
    "    hidden_dim=RM_HIDDEN_DIM,\n",
    "    head_type=RM_HEAD_TYPE,\n",
    "    dropout=RM_DROPOUT\n",
    ")\n",
    "\n",
    "reward_model.reward_head = reward_model.reward_head.to('cuda:0').to(torch.bfloat16)\n",
    "\n",
    "# Recreate optimizer and scheduler\n",
    "trainable_params = [p for p in reward_model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.AdamW(\n",
    "    trainable_params,\n",
    "    lr=RM_LEARNING_RATE,\n",
    "    weight_decay=RM_WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "num_training_steps = len(train_loader) * RM_EPOCHS // RM_GRADIENT_ACCUMULATION_STEPS\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"cosine\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=num_training_steps // 10,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Model reloaded with fresh state\")\n",
    "print(f\"✅ Loss function: bradley_terry_loss(chosen, rejected, margin=0.5)\")\n",
    "print(f\"✅ Ready to train with STRONG preference differentiation!\")\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"  - Epochs: {RM_EPOCHS}\")\n",
    "print(f\"  - Batch size: {RM_BATCH_SIZE}\")\n",
    "print(f\"  - Learning rate: {RM_LEARNING_RATE:.2e}\")\n",
    "print(f\"  - Margin requirement: 0.5 (chosen must be ≥0.5 higher than rejected)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "725cfdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Monitor class defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# GPU MONITORING - Real-time GPU usage during training\n",
    "import subprocess\n",
    "import threading\n",
    "\n",
    "class GPUMonitor:\n",
    "    \"\"\"Monitor GPU usage in real-time during training\"\"\"\n",
    "    def __init__(self, interval=10):\n",
    "        self.interval = interval\n",
    "        self.is_running = False\n",
    "        self.gpu_usage = []\n",
    "        self.thread = None\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Start monitoring in background thread\"\"\"\n",
    "        self.is_running = True\n",
    "        self.thread = threading.Thread(target=self._monitor_loop, daemon=True)\n",
    "        self.thread.start()\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"Stop monitoring\"\"\"\n",
    "        self.is_running = False\n",
    "        if self.thread:\n",
    "            self.thread.join(timeout=5)\n",
    "    \n",
    "    def _monitor_loop(self):\n",
    "        \"\"\"Background monitoring loop\"\"\"\n",
    "        while self.is_running:\n",
    "            try:\n",
    "                output = subprocess.check_output([\n",
    "                    'nvidia-smi', '--query-gpu=index,memory.used,memory.total,utilization.gpu',\n",
    "                    '--format=csv,noheader,nounits'\n",
    "                ]).decode('utf-8')\n",
    "                \n",
    "                gpu_stats = []\n",
    "                for line in output.strip().split('\\n'):\n",
    "                    parts = line.split(',')\n",
    "                    if len(parts) >= 3:\n",
    "                        gpu_idx = parts[0].strip()\n",
    "                        mem_used = float(parts[1].strip())\n",
    "                        mem_total = float(parts[2].strip())\n",
    "                        util = float(parts[3].strip()) if len(parts) > 3 else 0\n",
    "                        gpu_stats.append({\n",
    "                            'gpu': gpu_idx,\n",
    "                            'mem_used': mem_used,\n",
    "                            'mem_total': mem_total,\n",
    "                            'util': util\n",
    "                        })\n",
    "                \n",
    "                self.gpu_usage.append(gpu_stats)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            time.sleep(self.interval)\n",
    "    \n",
    "    def summary(self):\n",
    "        \"\"\"Print GPU usage summary\"\"\"\n",
    "        if not self.gpu_usage:\n",
    "            print(\"No GPU data collected\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"GPU USAGE SUMMARY (during training)\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Get stats per GPU\n",
    "        gpu_stats = {}\n",
    "        for reading in self.gpu_usage:\n",
    "            for stat in reading:\n",
    "                gpu = stat['gpu']\n",
    "                if gpu not in gpu_stats:\n",
    "                    gpu_stats[gpu] = {'util': [], 'mem': []}\n",
    "                gpu_stats[gpu]['util'].append(stat['util'])\n",
    "                gpu_stats[gpu]['mem'].append(stat['mem_used'])\n",
    "        \n",
    "        # Print summary\n",
    "        for gpu_idx in sorted(gpu_stats.keys()):\n",
    "            stats = gpu_stats[gpu_idx]\n",
    "            avg_util = sum(stats['util']) / len(stats['util']) if stats['util'] else 0\n",
    "            avg_mem = sum(stats['mem']) / len(stats['mem']) if stats['mem'] else 0\n",
    "            max_util = max(stats['util']) if stats['util'] else 0\n",
    "            max_mem = max(stats['mem']) if stats['mem'] else 0\n",
    "            \n",
    "            print(f\"\\nGPU {gpu_idx}:\")\n",
    "            print(f\"  Utilization: Avg {avg_util:.1f}%, Max {max_util:.1f}%\")\n",
    "            print(f\"  Memory Used: Avg {avg_mem:.0f} MiB, Max {max_mem:.0f} MiB\")\n",
    "            \n",
    "            # Determine if GPU was actually used\n",
    "            if avg_util > 5:\n",
    "                print(f\"  Status: ✓ ACTIVELY USED\")\n",
    "            else:\n",
    "                print(f\"  Status: ⚠️  IDLE (not actively used)\")\n",
    "\n",
    "print(\"GPU Monitor class defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e63d0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Training on both GPUs (distributed via auto device_map)\n",
      "\n",
      "================================================================================\n",
      "PRE-TRAINING GPU STATUS:\n",
      "================================================================================\n",
      "0, NVIDIA GeForce RTX 5090, 5987 MiB, 32607 MiB\n",
      "1, NVIDIA GeForce RTX 5090, 3247 MiB, 32607 MiB\n",
      "\n",
      "Starting training (FRESH START with fixed validation)...\n",
      "\n",
      "\n",
      "Epoch 1/3\n",
      "================================================================================\n",
      "Training on 82108 preference pairs (English + French)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/5132 [00:01<1:27:14,  1.02s/it, loss=1.1328, acc=0.2500, lr=0.00e+00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] Batch 0 - First 5 samples:\n",
      "  Chosen rewards: [ 0.7109375  -0.51953125  1.734375    1.9296875   0.5703125 ]\n",
      "  Rejected rewards: [ 1.625       1.5703125   0.3515625   1.515625   -0.37695312]\n",
      "  Difference (should be positive): [-0.9140625 -2.09375    1.3828125  0.4140625  0.9453125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5132/5132 [1:21:00<00:00,  1.06it/s, loss=0.7055, acc=0.4332, lr=1.26e-05]\n",
      "Training: 100%|██████████| 5132/5132 [1:21:00<00:00,  1.06it/s, loss=0.7055, acc=0.4332, lr=1.26e-05]\n",
      "Validation: 100%|██████████| 571/571 [06:42<00:00,  1.42it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.7055 | Train Acc: 0.4332 (EN + FR)\n",
      "Val Loss: 0.6953 | Val Acc: 0.0032 (EN + FR)\n",
      "\n",
      "⏱️  Time - Epoch: 1:27:43, Total: 1:27:43, Remaining: 2:55:27\n",
      "\n",
      "✓ New best validation accuracy: 0.0032\n",
      "Saving model to models/reward_model_coldstart...\n",
      "\n",
      "Epoch 2/3\n",
      "================================================================================\n",
      "Training on 82108 preference pairs (English + French)\n",
      "\n",
      "Epoch 2/3\n",
      "================================================================================\n",
      "Training on 82108 preference pairs (English + French)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/5132 [00:00<1:21:50,  1.04it/s, loss=0.6914, acc=0.3750, lr=1.26e-05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] Batch 0 - First 5 samples:\n",
      "  Chosen rewards: [-0.0300293  -0.02709961 -0.06494141 -0.03564453 -0.06494141]\n",
      "  Rejected rewards: [-0.06494141 -0.05126953 -0.06494141 -0.06494141 -0.06494141]\n",
      "  Difference (should be positive): [0.03491211 0.02416992 0.         0.02929688 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|███▉      | 2048/5132 [32:18<49:31,  1.04it/s, loss=0.6911, acc=0.3596, lr=9.66e-06]  "
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "# Use cuda:0 as primary device (both GPUs will be used via auto device_map)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Training on both GPUs (distributed via auto device_map)\")\n",
    "\n",
    "# Check GPU status BEFORE training\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PRE-TRAINING GPU STATUS:\")\n",
    "print(\"=\" * 80)\n",
    "os.system('nvidia-smi --query-gpu=index,name,memory.used,memory.total --format=csv,noheader | head -2')\n",
    "\n",
    "# Start GPU monitoring in background\n",
    "gpu_monitor = GPUMonitor(interval=5)\n",
    "gpu_monitor.start()\n",
    "\n",
    "print(\"\\nStarting training (FRESH START with fixed validation)...\\n\")\n",
    "best_val_accuracy = 0  # RESET from previous run\n",
    "training_start_time = time.time()\n",
    "\n",
    "try:\n",
    "    for epoch in range(RM_EPOCHS):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch + 1}/{RM_EPOCHS}\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Training on {len(train_data)} preference pairs (English + French)\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            reward_model,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            lr_scheduler,\n",
    "            device,\n",
    "            gradient_accumulation_steps=RM_GRADIENT_ACCUMULATION_STEPS\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc = validate(reward_model, val_loader, device)\n",
    "        \n",
    "        # Calculate timing\n",
    "        epoch_elapsed = time.time() - epoch_start_time\n",
    "        total_elapsed = time.time() - training_start_time\n",
    "        epochs_completed = epoch + 1\n",
    "        epochs_remaining = RM_EPOCHS - epochs_completed\n",
    "        estimated_remaining = (total_elapsed / epochs_completed) * epochs_remaining\n",
    "        \n",
    "        print(f\"\\nTrain Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} (EN + FR)\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} (EN + FR)\")\n",
    "        print(f\"\\n⏱️  Time - Epoch: {timedelta(seconds=int(epoch_elapsed))}, \"\n",
    "              f\"Total: {timedelta(seconds=int(total_elapsed))}, \"\n",
    "              f\"Remaining: {timedelta(seconds=int(estimated_remaining))}\")\n",
    "        \n",
    "        # Log to wandb\n",
    "        if USE_WANDB:\n",
    "            wandb.log({\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'train_accuracy': train_acc,\n",
    "                'val_loss': val_loss,\n",
    "                'val_accuracy': val_acc\n",
    "            })\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_accuracy:\n",
    "            best_val_accuracy = val_acc\n",
    "            print(f\"\\n✓ New best validation accuracy: {best_val_accuracy:.4f}\")\n",
    "            print(f\"Saving model to {REWARD_MODEL_COLD_START}...\")\n",
    "            \n",
    "            # Save model\n",
    "            REWARD_MODEL_COLD_START.mkdir(exist_ok=True, parents=True)\n",
    "            \n",
    "            torch.save({\n",
    "                'model_state_dict': reward_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'val_accuracy': val_acc,\n",
    "                'config': {\n",
    "                    'base_model': REWARD_BASE_MODEL,\n",
    "                    'head_type': RM_HEAD_TYPE,\n",
    "                    'hidden_dim': RM_HIDDEN_DIM\n",
    "                }\n",
    "            }, REWARD_MODEL_COLD_START / \"reward_model.pt\")\n",
    "            \n",
    "            # Save tokenizer\n",
    "            rm_tokenizer.save_pretrained(REWARD_MODEL_COLD_START)\n",
    "\n",
    "finally:\n",
    "    # Stop GPU monitoring\n",
    "    gpu_monitor.stop()\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"Training complete!\")\n",
    "print(f\"Best validation accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "# Final training time\n",
    "total_training_time = time.time() - training_start_time\n",
    "avg_time_per_epoch = total_training_time / RM_EPOCHS\n",
    "print(f\"\\n⏱️  Total Training Time: {timedelta(seconds=int(total_training_time))}\")\n",
    "print(f\"    Average per epoch: {timedelta(seconds=int(avg_time_per_epoch))}\")\n",
    "\n",
    "# Print GPU usage summary\n",
    "gpu_monitor.summary()\n",
    "\n",
    "print(f\"\\nModel trained jointly on:\")\n",
    "print(f\"  • English → Arabic preferences\")\n",
    "print(f\"  • French → Arabic preferences\")\n",
    "\n",
    "if USE_WANDB:\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4eb8b8",
   "metadata": {},
   "source": [
    "## Test Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d27d842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained reward model\n",
    "reward_model.eval()\n",
    "\n",
    "print(\"Testing reward model on sample translations...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get some test examples\n",
    "test_samples = random.sample(val_data, min(5, len(val_data)))\n",
    "\n",
    "for i, sample in enumerate(test_samples, 1):\n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(f\"Source: {sample['source'][:100]}...\")\n",
    "    \n",
    "    # Prepare inputs\n",
    "    chosen_text = f\"Source: {sample['source']}\\nTranslation: {sample['chosen']}\"\n",
    "    rejected_text = f\"Source: {sample['source']}\\nTranslation: {sample['rejected']}\"\n",
    "    \n",
    "    chosen_tokens = rm_tokenizer(\n",
    "        chosen_text,\n",
    "        max_length=RM_MAX_LENGTH,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "    \n",
    "    rejected_tokens = rm_tokenizer(\n",
    "        rejected_text,\n",
    "        max_length=RM_MAX_LENGTH,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "    \n",
    "    # Get rewards\n",
    "    with torch.no_grad():\n",
    "        chosen_reward = reward_model(\n",
    "            chosen_tokens['input_ids'],\n",
    "            chosen_tokens['attention_mask']\n",
    "        ).item()\n",
    "        \n",
    "        rejected_reward = reward_model(\n",
    "            rejected_tokens['input_ids'],\n",
    "            rejected_tokens['attention_mask']\n",
    "        ).item()\n",
    "    \n",
    "    print(f\"\\nChosen translation: {sample['chosen'][:100]}...\")\n",
    "    print(f\"Chosen reward: {chosen_reward:.4f} (original score: {sample['chosen_score']:.4f})\")\n",
    "    \n",
    "    print(f\"\\nRejected translation: {sample['rejected'][:100]}...\")\n",
    "    print(f\"Rejected reward: {rejected_reward:.4f} (original score: {sample['rejected_score']:.4f})\")\n",
    "    \n",
    "    print(f\"\\nReward margin: {chosen_reward - rejected_reward:.4f}\")\n",
    "    print(f\"Correct preference: {'✓' if chosen_reward > rejected_reward else '✗'}\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a20df7",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "\n",
    "Proceed to **notebook 3** to run PPO optimization using this trained reward model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

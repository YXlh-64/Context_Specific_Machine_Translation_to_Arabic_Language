# RAG Translation Agent - Gemini API# RAG Translation Agent - Context-Specific Machine Translation to Arabic



A Retrieval-Augmented Generation (RAG) system for English-to-Arabic translation using Google's Gemini API with context-aware translation.## ğŸ¯ Project Overview



## ğŸ¯ What is This?This project implements a **Retrieval-Augmented Generation (RAG)** system for context-aware English-to-Arabic translation, specifically optimized for economic and financial domain texts. The system combines semantic search with neural machine translation to deliver domain-specific, consistent, and accurate translations.



This system combines:### What Makes This "Agentic"?

- **Vector Database** (FAISS) with 1.8M+ economic translation pairs

- **Sentence Embeddings** for semantic similarity searchThe **agentic** nature of this system lies in its autonomous decision-making and multi-step reasoning process:

- **Google Gemini API** for context-aware translation

- **RAG Pipeline** that retrieves similar examples to improve translation quality1. **Autonomous Context Retrieval**: The agent independently determines which translation examples are most relevant by:

   - Semantically analyzing the input text

## ğŸš€ Quick Start   - Querying the vector database for similar examples

   - Ranking and selecting the most contextually appropriate examples

### 1. Installation

2. **Adaptive Translation Strategy**: Based on retrieved context, the agent:

```bash   - Dynamically adjusts its translation approach

# Install dependencies   - Incorporates domain-specific terminology

pip install -r requirements.txt   - Maintains consistency with similar past translations

```

3. **Multi-Step Pipeline Orchestration**: The agent autonomously coordinates:

### 2. Get Gemini API Key   - Text normalization and preprocessing

   - Semantic retrieval operations

1. Visit: https://makersuite.google.com/app/apikey   - Context formatting and prompt construction

2. Create a free API key   - Translation generation with appropriate parameters

3. Set environment variable:   - Post-processing and result validation



```bash4. **Self-Optimization**: The system can:

export GOOGLE_API_KEY="your_api_key_here"   - Filter results based on domain metadata

```   - Adjust retrieval parameters (top-k, similarity thresholds)

   - Select between different translation models

### 3. Build Vector Database (First Time Only)   - Apply quantization strategies based on available resources



```bashThis goes beyond a simple translation API by acting as an intelligent agent that makes contextual decisions at each step to optimize translation quality.

python build_vector_db.py --config config.ini --sample 10000

```---



This indexes translation examples from `economic v1.csv` for retrieval.## ğŸ“Š Data Source



### 4. Test Translation### Economic v1.csv - UN Parallel Corpus



```bashThe system is trained and retrieves context from `economic v1.csv`, a parallel corpus containing:

python test_gemini.py

```- **Source**: English text from UN documents (economic and financial domain)

- **Target**: Professional Arabic translations

### 5. Run Evaluation- **Size**: Contains thousands of parallel sentence pairs

- **Domain**: Economic, financial, legal, and political terminology

```bash- **Structure**:

# Extract test samples  - `id`: Unique identifier for each translation pair

python extract_test_samples.py --num_samples 100  - `en`: English source text

  - `ar`: Arabic target translation

# Compare RAG vs non-RAG

python compare_rag.py \**Example entries**:

    --api_key $GOOGLE_API_KEY \```csv

    --test_file test_samples.csv \id,en,ar

    --sample 1001,"The question of financial assistance to defendants unable to fund their defence...","ÙˆÙ‡Ù†Ø§Ùƒ Ø­Ø§Ø¬Ø© Ø£ÙŠØ¶Ø§ Ø§Ù„Ù‰ Ø§Ù„Ù†Ø¸Ø± ÙÙŠ Ù…Ø³Ø£Ù„Ø© ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø§Ù„ÙŠØ©..."

```9,"It is estimated that the cost of maintaining UNFICYP...","ØªØ´ÙŠØ± Ø§Ù„ØªÙ‚Ø¯ÙŠØ±Ø§Øª Ø§Ù„Ù‰ Ø£Ù† ØªÙƒØ§Ù„ÙŠÙ Ø§ï»¹Ø¨Ù‚Ø§Ø¡ Ø¹Ù„Ù‰ Ù‚ÙˆØ©..."

```

## ğŸ“Š How It Works

This high-quality parallel corpus serves as:

### RAG Translation Pipeline1. **Training data** for building the vector database

2. **Retrieval source** for finding similar translation contexts

```3. **Quality reference** for domain-specific terminology

Input Text

    â†“---

1. Normalize & Preprocess

    â†“## ğŸ—ï¸ System Architecture

2. Generate Embedding (Sentence-BERT)

    â†“```

3. Search Vector DB (FAISS)â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

    â†“â”‚                         User Interface Layer                      â”‚

4. Retrieve Top-K Similar Examplesâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚

    â†“â”‚  â”‚  Streamlit UI  â”‚  â”‚   Python API   â”‚  â”‚  CLI Scripts      â”‚ â”‚

5. Build Context Prompt with Examplesâ”‚  â”‚   (app.py)     â”‚  â”‚ (rag_agent.py) â”‚  â”‚ (example.py)      â”‚ â”‚

    â†“â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚

6. Send to Gemini APIâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â†“                              â†“

7. Get Context-Aware Translationâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

    â†“â”‚                     RAG Agent (Orchestrator)                      â”‚

Output Translationâ”‚                         rag_agent.py                              â”‚

```â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚

â”‚  â”‚  1. Text Normalization                                    â”‚  â”‚

### Exampleâ”‚  â”‚  2. Context Retrieval (semantic search)                   â”‚  â”‚

â”‚  â”‚  3. Prompt Construction (with retrieved examples)         â”‚  â”‚

**Without RAG (Baseline)**:â”‚  â”‚  4. Translation Generation                                â”‚  â”‚

```â”‚  â”‚  5. Result Post-processing                                â”‚  â”‚

Input: "The economic growth rate increased significantly."â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚

Output: [Generic translation]â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```              â†“                                â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

**With RAG (Context-Aware)**:â”‚   Retrieval Component      â”‚    â”‚   Translation Component      â”‚

```â”‚     vector_db.py           â”‚    â”‚      Transformers            â”‚

Input: "The economic growth rate increased significantly."â”‚                            â”‚    â”‚                              â”‚

â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚

Retrieved Examples:â”‚  â”‚ Embedding Model      â”‚ â”‚    â”‚  â”‚ Translation Models     â”‚ â”‚

1. "Economic indicators show positive trends" â†’ "ØªØ¸Ù‡Ø± Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ© Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©"â”‚  â”‚ â€¢ Sentence-BERT      â”‚ â”‚    â”‚  â”‚ â€¢ MarianMT (default)   â”‚ â”‚

2. "The growth rate exceeds expectations" â†’ "Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù…Ùˆ ÙŠØªØ¬Ø§ÙˆØ² Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª"â”‚  â”‚ â€¢ Multilingual       â”‚ â”‚    â”‚  â”‚ â€¢ NLLB                 â”‚ â”‚

3. "GDP growth accelerated" â†’ "ØªØ³Ø§Ø±Ø¹ Ù†Ù…Ùˆ Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ"â”‚  â”‚ â€¢ 768D vectors       â”‚ â”‚    â”‚  â”‚ â€¢ QWEN (fine-tuned)    â”‚ â”‚

â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚

Output: [Domain-specific, consistent translation using economic terminology]â”‚                            â”‚    â”‚                              â”‚

```â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚

â”‚  â”‚ Vector Database      â”‚ â”‚    â”‚  â”‚ Generation Config      â”‚ â”‚

## ğŸ“ File Structureâ”‚  â”‚ â€¢ ChromaDB           â”‚ â”‚    â”‚  â”‚ â€¢ Beam search          â”‚ â”‚

â”‚  â”‚ â€¢ FAISS (GPU-accel.) â”‚ â”‚    â”‚  â”‚ â€¢ Temperature tuning   â”‚ â”‚

```â”‚  â”‚ â€¢ Cosine similarity  â”‚ â”‚    â”‚  â”‚ â€¢ Top-p sampling       â”‚ â”‚

RAG_Agent/â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚

â”œâ”€â”€ rag_agent.py              # Main translation agent (Gemini API)â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”œâ”€â”€ vector_db.py              # FAISS vector database manager              â†“

â”œâ”€â”€ utils.py                  # Utilities (normalization, formatting)â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”œâ”€â”€ config.ini                # Configuration settingsâ”‚                      Data Storage Layer                           â”‚

â”‚â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚

â”œâ”€â”€ build_vector_db.py        # Build/update vector databaseâ”‚  â”‚  Vector Index   â”‚  â”‚  Metadata Store  â”‚  â”‚  Economic Data â”‚ â”‚

â”œâ”€â”€ test_gemini.py            # Quick test scriptâ”‚  â”‚  (embeddings)   â”‚  â”‚   (text pairs)   â”‚  â”‚ (economic.csv) â”‚ â”‚

â”œâ”€â”€ compare_rag.py            # Evaluation with metrics (BLEU, chrF)â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚

â”œâ”€â”€ extract_test_samples.py   # Extract test dataâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”‚```

â”œâ”€â”€ app.py                    # Streamlit web UI (optional)

â”œâ”€â”€ evaluate.py               # Full evaluation suite---

â”œâ”€â”€ requirements.txt          # Python dependencies

â”‚## ğŸ”„ RAG Process Explained

â”œâ”€â”€ economic v1.csv           # Translation corpus (1.8M pairs)

â””â”€â”€ vector_db/                # FAISS index files### Step-by-Step Translation Pipeline

    â””â”€â”€ translation_corpus.index

```#### 1. **Input Processing** (`utils.py`)

```

## ğŸ”§ ConfigurationUser Input: "The GDP growth rate increased by 3.5% in Q2 2024"

                    â†“

Edit `config.ini`:        [Text Normalization]

                    â†“

```iniNormalized: "The GDP growth rate increased by 3.5% in Q2 2024"

[GEMINI]```

model_name = gemini-pro

temperature = 0.3#### 2. **Semantic Embedding** (`vector_db.py`)

top_k_retrieval = 3```

max_output_tokens = 512Normalized Text â†’ Sentence-BERT Encoder â†’ 768D Vector

[0.023, -0.145, 0.892, ..., 0.334]

[VECTOR_DB]```

db_type = faiss

collection_name = translation_corpus#### 3. **Context Retrieval** (`vector_db.py`)

The vector database searches for similar translation examples:

[EMBEDDINGS]```

model_name = sentence-transformers/paraphrase-multilingual-mpnet-base-v2Query Vector â†’ Vector Database (FAISS/ChromaDB)

device = cuda                    â†“

```    [Cosine Similarity Search]

                    â†“

## ğŸ’» UsageTop-5 Similar Examples (from economic v1.csv):

1. "The economic growth rate increased..." â†’ "Ø§Ø±ØªÙØ¹ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ..."

### Python API2. "GDP estimates for the quarter..." â†’ "ØªÙ‚Ø¯ÙŠØ±Ø§Øª Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù„Ù„Ø±Ø¨Ø¹..."

3. "Growth statistics show..." â†’ "ØªØ¸Ù‡Ø± Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø§Ù„Ù†Ù…Ùˆ..."

```python4. "Financial indicators improved..." â†’ "ØªØ­Ø³Ù†Øª Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©..."

from rag_agent import RAGTranslationAgent5. "The rate of increase..." â†’ "Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø²ÙŠØ§Ø¯Ø©..."

from vector_db import VectorDBManager```

from utils import load_config

#### 4. **Prompt Construction** (`rag_agent.py`)

# Load config```

config = load_config("config.ini")System: You are a professional translator specializing in economic texts.



# Initialize vector databaseContext (Similar Examples):

vector_db = VectorDBManager(- EN: "The economic growth rate increased..."

    db_type="faiss",  AR: "Ø§Ø±ØªÙØ¹ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ..."

    embedding_model=config.get("EMBEDDINGS", "model_name"),- EN: "GDP estimates for the quarter..."

    db_path="./vector_db",  AR: "ØªÙ‚Ø¯ÙŠØ±Ø§Øª Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù„Ù„Ø±Ø¨Ø¹..."

    device="cuda"[... more examples ...]

)

Now translate:

# Initialize translation agentEN: "The GDP growth rate increased by 3.5% in Q2 2024"

agent = RAGTranslationAgent(AR: 

    api_key="YOUR_GEMINI_API_KEY",  # or use env var```

    vector_db_manager=vector_db,

    model_name="gemini-pro",#### 5. **Translation Generation** (`rag_agent.py`)

    temperature=0.3,```

    top_k_retrieval=3Prompt â†’ Translation Model (MarianMT/NLLB/QWEN)

)                    â†“

        [Beam Search Decoding]

# Translate with RAG        [Context-Aware Generation]

result = agent.translate(                    â†“

    "The economic growth rate increased significantly.",Arabic Translation: "Ø§Ø±ØªÙØ¹ Ù…Ø¹Ø¯Ù„ Ù†Ù…Ùˆ Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¨Ù†Ø³Ø¨Ø© 3.5% ÙÙŠ Ø§Ù„Ø±Ø¨Ø¹ Ø§Ù„Ø«Ø§Ù†ÙŠ Ù…Ù† Ø¹Ø§Ù… 2024"

    use_context=True,```

    return_context=True

)#### 6. **Post-Processing** (`utils.py`)

```

print(f"Translation: {result['translation']}")Raw Output â†’ [Normalization] â†’ Final Translation

print(f"Used {result['num_retrieved']} context examples")```

```

### Why RAG Improves Translation

### Command Line

**Without RAG** (baseline model):

```bash```

# Quick testInput: "The GDP growth rate increased by 3.5%"

python test_gemini.pyOutput: "Ø²Ø§Ø¯ Ù…Ø¹Ø¯Ù„ Ù†Ù…Ùˆ Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø¨Ù†Ø³Ø¨Ø© 3.5Ùª"

        (Generic translation, inconsistent terminology)

# Full evaluation```

python compare_rag.py --api_key $GOOGLE_API_KEY --test_file test.csv

**With RAG** (context-aware):

# Web UI```

streamlit run app.pyInput: "The GDP growth rate increased by 3.5%"

```Retrieved Context: Similar economic translations from UN corpus

Output: "Ø§Ø±ØªÙØ¹ Ù…Ø¹Ø¯Ù„ Ù†Ù…Ùˆ Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¨Ù†Ø³Ø¨Ø© 3.5Ùª"

## ğŸ“ˆ Evaluation Metrics        (Domain-specific, consistent with UN terminology)

```

The system evaluates translation quality using:

---

- **BLEU Score**: Precision-based metric (0-100)

- **chrF Score**: Character n-gram F-score (0-100)## ğŸ“ File Structure and Purpose



### Expected Results### Core Components



```#### 1. **`rag_agent.py`** - The Orchestrator

ğŸ“Š RESULTS COMPARISON**Purpose**: Main agentic component that coordinates the entire RAG pipeline.

============================================================

**Key Responsibilities**:

ğŸ”µ WITHOUT RAG (Baseline):- Manages the translation workflow

   BLEU Score:  42.35- Coordinates retrieval and generation

   chrF Score:  65.78- Handles different model types (Seq2Seq, Causal LM)

- Implements context-aware prompting

ğŸŸ¢ WITH RAG (Context-Aware):- Batch processing support

   BLEU Score:  58.92

   chrF Score:  78.43**Key Class**: `RAGTranslationAgent`

- **Methods**:

ğŸ“ˆ IMPROVEMENT:  - `translate()`: Single text translation with RAG

   BLEU: +16.57 points (+39.1%)  - `translate_batch()`: Batch translation processing

   chrF: +12.65 points (+19.2%)  - `_translate_seq2seq()`: For MarianMT, NLLB models

```  - `_translate_causal()`: For QWEN, LLaMA models



## ğŸ“ Key Features**Agentic Features**:

- Autonomous context retrieval decisions

### Why RAG?- Dynamic prompt construction based on retrieved examples

- Adaptive generation parameters

1. **Domain Adaptation**: Uses economic/financial terminology from corpus

2. **Consistency**: Learns translation style from retrieved examples#### 2. **`vector_db.py`** - The Memory System

3. **Context-Aware**: Better handling of idiomatic expressions**Purpose**: Manages semantic search and retrieval from the parallel corpus.

4. **Dynamic**: No model retraining needed for new domains

**Key Responsibilities**:

### Why Gemini API?- Build vector database from `economic v1.csv`

- Generate embeddings for source texts

1. **Causal Language Model**: Excels at in-context learning- Perform semantic similarity search

2. **Few-Shot Learning**: Effectively uses retrieved examples- Handle both ChromaDB and FAISS backends

3. **Easy Setup**: No local GPU requirements

4. **Free Tier**: 60 requests/min, 1,500/day**Key Class**: `VectorDBManager`

- **Methods**:

## ğŸ” Comparison with MarianMT  - `build_from_dataframe()`: Index the economic corpus

  - `retrieve()`: Semantic search for similar translations

| Feature | MarianMT (Previous) | Gemini + RAG (Current) |  - `add_examples()`: Add new translation pairs

|---------|---------------------|------------------------|  - `_initialize_chromadb()` / `_initialize_faiss()`: Backend setup

| **Architecture** | Seq2Seq Encoder-Decoder | Causal Language Model |

| **Context Usage** | âŒ Can't use retrieved examples | âœ… Leverages RAG context |**Supported Backends**:

| **Domain Adaptation** | âŒ Fixed at training | âœ… Dynamic via retrieval |- **ChromaDB**: Easy persistence, good for <10M documents

| **Setup** | Complex (quantization issues) | Simple (API key) |- **FAISS**: Ultra-fast search, GPU-accelerated, scalable

| **Hardware** | Requires GPU | API-based (no GPU needed) |

| **Translation Quality** | Good | Better with context |#### 3. **`utils.py`** - Helper Functions

**Purpose**: Common utilities for text processing and configuration.

## ğŸ› Troubleshooting

**Key Functions**:

### API Key Error- `normalize_english_text()`: Clean and normalize English input

- `normalize_arabic_text()`: Clean and normalize Arabic output

```bash- `format_context_examples()`: Format retrieved examples for prompts

# Check if set- `chunk_text()`: Handle long texts

echo $GOOGLE_API_KEY- `load_config()`: Configuration management

- `setup_logging()`: Logging infrastructure

# Set it

export GOOGLE_API_KEY="your_key_here"### Scripts and Tools

```

#### 4. **`build_vector_db.py`** - Database Builder

### Rate Limit Error**Purpose**: Process `economic v1.csv` and build the searchable vector database.



```python**Usage**:

# Add delay between requests```bash

import time# Build from economic corpus

time.sleep(1)  # 1 second = 60 req/minpython build_vector_db.py --config config.ini

```

# Test with sample

### Import Errorpython build_vector_db.py --sample 1000

```

```bash

# Reinstall package**What It Does**:

pip install --upgrade google-generativeai1. Reads `economic v1.csv` (EN-AR parallel sentences)

```2. Generates embeddings for English sentences

3. Creates vector index (ChromaDB or FAISS)

### Poor Translation Quality4. Stores metadata (EN text, AR translation, domains)

5. Saves to disk for retrieval

1. Increase `top_k_retrieval` (try 5-7)

2. Lower `temperature` (try 0.1-0.2)**Output**: Vector database in `./vector_db/` directory

3. Rebuild vector DB with more samples

#### 5. **`evaluate.py`** - Evaluation Suite

## ğŸ“Š Dataset**Purpose**: Measure translation quality with and without RAG.



**economic v1.csv**: 1,799,855 parallel EN-AR sentence pairs**Metrics**:

- Source: UN documents and economic reports- **BLEU**: N-gram overlap score (0-100)

- Domain: Economics, finance, international development- **chrF**: Character-level F-score (0-100)

- Format: CSV with columns: `id`, `en`, `ar`

**Usage**:

## ğŸš€ API Usage```bash

# Evaluate on test set

**Gemini API Free Tier:**python evaluate.py --config config.ini --test_file test_data.csv

- 60 requests per minute

- 1,500 requests per day# Compare RAG vs baseline

- Free foreverpython evaluate.py --compare_baseline

```

**For 100 test samples:**

- Baseline: 100 requests**Output**:

- RAG: 100 requests- Aggregate metrics (BLEU, chrF)

- **Total: 200 requests** (~3.5 minutes)- Per-example results

- RAG improvement statistics

## ğŸ“ License- Sample translations



This project uses:#### 6. **`app.py`** - Web Interface

- Google Gemini API (subject to Google's terms)**Purpose**: Interactive Streamlit demo for the translation system.

- Open-source dependencies (see requirements.txt)

**Features**:

## ğŸ¤ Contributing- Single text translation

- Batch translation (CSV upload)

To improve the system:- Context visualization (shows retrieved examples)

1. Tune hyperparameters in `config.ini`- Export results to CSV/JSON

2. Try different Gemini models (gemini-1.5-flash, etc.)- Real-time translation

3. Add domain-specific corpora to vector DB- Configuration options

4. Experiment with prompt templates

**Usage**:

## ğŸ“š References```bash

streamlit run app.py

- [Gemini API Documentation](https://ai.google.dev/docs)```

- [FAISS Documentation](https://github.com/facebookresearch/faiss)

- [Sentence-BERT](https://www.sbert.net/)**Interface Sections**:

- [RAG Paper](https://arxiv.org/abs/2005.11401)- Text input area

- Translation button

---- Results display (Arabic output)

- Retrieved context panel

âœ… **Ready to translate with context-aware RAG!**- Statistics and metrics



For questions or issues, check the logs in `./logs/` or review the configuration in `config.ini`.#### 7. **`example.py`** - Usage Examples

**Purpose**: Simple demonstrations and quick testing.

**Examples Included**:
- Basic translation
- Batch processing
- Custom configuration
- Error handling
- Performance testing

**Usage**:
```bash
python example.py
```

### Configuration

#### 8. **`config.ini`** - System Configuration
**Purpose**: Centralized configuration for all components.

**Key Sections**:

```ini
[GENERAL]
vector_db_dir = ./vector_db        # Where to store/load vector DB
logs_dir = ./logs                  # Logging directory
corpus_file = ./economic v1.csv    # Path to parallel corpus

[EMBEDDINGS]
model_name = sentence-transformers/paraphrase-multilingual-mpnet-base-v2
device = cuda                      # cuda, cpu, or mps
batch_size = 32                    # Embedding batch size

[VECTOR_DB]
db_type = faiss                    # chromadb or faiss
collection_name = translation_corpus
top_k = 5                          # Number of examples to retrieve

[TRANSLATION]
model_name = Helsinki-NLP/opus-mt-en-ar
device = cuda
max_length = 512
num_beams = 5                      # Beam search width
temperature = 0.7                  # Sampling temperature
top_p = 0.9                        # Nucleus sampling
use_4bit = false                   # 4-bit quantization
use_8bit = false                   # 8-bit quantization
```

#### 9. **`requirements.txt`** - Dependencies
**Purpose**: All Python package dependencies.

**Key Packages**:
```
torch>=2.0.0                       # PyTorch
transformers>=4.30.0               # HuggingFace models
sentence-transformers>=2.2.0       # Embedding models
chromadb>=0.4.0                    # ChromaDB backend
faiss-gpu>=1.7.2                   # FAISS GPU backend
streamlit>=1.25.0                  # Web UI
pandas>=1.5.0                      # Data processing
numpy>=1.24.0                      # Numerical operations
sacrebleu>=2.3.0                   # BLEU metric
```

### Setup Scripts

#### 10. **`setup.fish`** / **`setup.sh`** - Automated Setup
**Purpose**: One-command environment setup for Fish/Bash shells.

**What They Do**:
```bash
./setup.fish  # or ./setup.sh
```

1. Create Python virtual environment
2. Install all dependencies from `requirements.txt`
3. Verify GPU/CUDA setup
4. Create necessary directories
5. Check configuration

### Utility Scripts

#### 11. **`check_gpu.py`** - GPU Diagnostics
**Purpose**: Verify GPU/CUDA setup and provide recommendations.

**Usage**:
```bash
python check_gpu.py
```

**Checks**:
- PyTorch CUDA availability
- GPU device information
- VRAM availability
- FAISS GPU support
- Optimal configuration suggestions

---

## ğŸš€ Quick Start Guide

### Installation (2 minutes)

```bash
cd RAG_Agent

# Run automated setup
./setup.fish  # or ./setup.sh for bash

# Activate environment
source venv/bin/activate.fish
```

### Build Vector Database (5-10 minutes)

```bash
# Build from economic v1.csv
python build_vector_db.py --config config.ini

# Or test with sample first
python build_vector_db.py --sample 1000
```

This processes the `economic v1.csv` corpus and creates the vector index.

### Test the System (1 minute)

```bash
# Run example script
python example.py
```

### Launch Web Interface (30 seconds)

```bash
# Start Streamlit app
streamlit run app.py
```

Opens at `http://localhost:8501`

---

## ğŸ’» Usage Examples

### Python API - Basic Translation

```python
from rag_agent import RAGTranslationAgent
from vector_db import VectorDBManager

# Initialize vector database
vector_db = VectorDBManager(
    db_type="faiss",
    embedding_model="sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
    db_path="./vector_db"
)

# Initialize RAG agent
agent = RAGTranslationAgent(
    translation_model="Helsinki-NLP/opus-mt-en-ar",
    vector_db_manager=vector_db,
    top_k_retrieval=5
)

# Translate
result = agent.translate(
    "The economic growth rate increased by 3.5%",
    return_context=True
)

print(f"Translation: {result['translation']}")
print(f"Retrieved {len(result['context'])} examples")
```

### Batch Translation

```python
import pandas as pd

# Load test data
df = pd.read_csv("test_data.csv")

# Translate all English texts
results = agent.translate_batch(df['en'].tolist())

# Add translations to dataframe
df['ar_predicted'] = [r['translation'] for r in results]

# Save results
df.to_csv("translations_output.csv", index=False)
```

### Compare With/Without RAG

```python
# Translate with RAG (context-aware)
result_with_rag = agent.translate(
    "The GDP increased significantly",
    use_context=True
)

# Translate without RAG (baseline)
result_without_rag = agent.translate(
    "The GDP increased significantly",
    use_context=False
)

print("With RAG:", result_with_rag['translation'])
print("Without RAG:", result_without_rag['translation'])
```

---

## ğŸ“Š Evaluation

### Running Evaluation

```bash
# Evaluate on test set
python evaluate.py --test_file test_data.csv --config config.ini

# Compare RAG vs baseline
python evaluate.py --compare_baseline --output_file results.json
```

### Expected Results

**With RAG** (Context-Aware):
- BLEU: 45-55
- chrF: 65-75
- Better domain terminology
- More consistent translations

**Without RAG** (Baseline):
- BLEU: 35-45
- chrF: 55-65
- Generic translations
- Less consistent

---

## âš™ï¸ GPU/CUDA Support

### Check GPU Setup

```bash
python check_gpu.py
```

### GPU Configuration

For GPU acceleration, ensure `config.ini` has:

```ini
[EMBEDDINGS]
device = cuda

[TRANSLATION]
device = cuda
use_8bit = false  # Set true if <16GB VRAM
use_4bit = false  # Set true if <12GB VRAM
```

### FAISS GPU Acceleration

FAISS automatically uses GPU if available. Benefits:
- 10-20x faster retrieval
- Handles larger vector databases
- Reduced latency

---

## ğŸ”§ Customization

### Use Different Translation Models

```python
# Option 1: MarianMT (default, fast)
agent = RAGTranslationAgent(
    translation_model="Helsinki-NLP/opus-mt-en-ar",
    vector_db_manager=vector_db
)

# Option 2: NLLB (high quality, multilingual)
agent = RAGTranslationAgent(
    translation_model="facebook/nllb-200-distilled-600M",
    vector_db_manager=vector_db
)

# Option 3: Fine-tuned QWEN (best for domain)
agent = RAGTranslationAgent(
    translation_model="path/to/finetuned-qwen",
    vector_db_manager=vector_db
)
```

### Adjust Retrieval Parameters

```python
# More context examples
agent = RAGTranslationAgent(
    translation_model="Helsinki-NLP/opus-mt-en-ar",
    vector_db_manager=vector_db,
    top_k_retrieval=10  # Retrieve 10 examples instead of 5
)

# Domain-specific retrieval
result = agent.translate(
    "The GDP increased",
    domain="economic",  # Filter by domain
    top_k=7
)
```

### Custom Prompt Templates

```python
custom_prompt = """You are an expert economic translator.

Examples from UN corpus:
{context}

Translate this economic text to Arabic:
{source_text}

Translation:"""

agent = RAGTranslationAgent(
    translation_model="Helsinki-NLP/opus-mt-en-ar",
    vector_db_manager=vector_db,
    prompt_template=custom_prompt
)
```

---

## ğŸ› Troubleshooting

### Issue: "Vector database not found"

**Solution**: Build the database first:
```bash
python build_vector_db.py --config config.ini
```

### Issue: "CUDA out of memory"

**Solution**: Enable quantization in `config.ini`:
```ini
[TRANSLATION]
use_8bit = true
```

Or use CPU:
```ini
[TRANSLATION]
device = cpu
```

### Issue: "ChromaDB collection empty"

**Solution**: Rebuild the vector database:
```bash
python build_vector_db.py --clear_existing --config config.ini
```

### Issue: "Poor translation quality"

**Solutions**:
1. Increase `top_k` to retrieve more examples
2. Ensure `economic v1.csv` is properly loaded
3. Try different translation models
4. Check if RAG is enabled (`use_context=True`)

---

## ğŸ“ˆ Performance Tips

### For Speed
- Use FAISS instead of ChromaDB
- Enable GPU acceleration
- Use 8-bit quantization
- Reduce `top_k` to 3-5

### For Quality
- Increase `top_k` to 7-10
- Use larger translation models (NLLB)
- Ensure diverse training corpus
- Fine-tune on domain-specific data

### For Memory Efficiency
- Enable 4-bit quantization
- Use smaller embedding models
- Reduce batch sizes
- Use CPU if limited VRAM

---

## ğŸ”¬ How the Agentic System Works

### Agent Decision Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Input: English text to translate        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT DECISION 1: Text Analysis                 â”‚
â”‚ â€¢ Analyze semantic content                      â”‚
â”‚ â€¢ Identify domain (economic, legal, etc.)       â”‚
â”‚ â€¢ Determine complexity                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT DECISION 2: Retrieval Strategy            â”‚
â”‚ â€¢ How many examples to retrieve? (top_k)        â”‚
â”‚ â€¢ Should we filter by domain?                   â”‚
â”‚ â€¢ What similarity threshold?                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ACTION: Query Vector Database                   â”‚
â”‚ â€¢ Search economic v1.csv embeddings             â”‚
â”‚ â€¢ Rank by semantic similarity                   â”‚
â”‚ â€¢ Return top-k most relevant examples           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT DECISION 3: Context Selection              â”‚
â”‚ â€¢ Evaluate retrieved examples                   â”‚
â”‚ â€¢ Filter out low-quality matches                â”‚
â”‚ â€¢ Order by relevance                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT DECISION 4: Prompt Construction            â”‚
â”‚ â€¢ Format selected examples                      â”‚
â”‚ â€¢ Build context-aware prompt                    â”‚
â”‚ â€¢ Include domain-specific instructions          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT DECISION 5: Generation Strategy            â”‚
â”‚ â€¢ Select temperature for creativity             â”‚
â”‚ â€¢ Choose beam width for quality                 â”‚
â”‚ â€¢ Determine max length                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ACTION: Generate Translation                     â”‚
â”‚ â€¢ Input: Context + Source text                  â”‚
â”‚ â€¢ Process: Neural translation with context      â”‚
â”‚ â€¢ Output: Arabic translation                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT DECISION 6: Post-Processing                â”‚
â”‚ â€¢ Validate output quality                       â”‚
â”‚ â€¢ Normalize Arabic text                         â”‚
â”‚ â€¢ Check for errors                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Output: Context-aware translation        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Agentic Behaviors

1. **Autonomous Reasoning**: Makes decisions without human intervention at each step
2. **Context Awareness**: Understands when to use which examples based on semantic similarity
3. **Adaptive Strategy**: Adjusts parameters based on input characteristics
4. **Goal-Oriented**: Works towards producing the best domain-specific translation
5. **Self-Monitoring**: Validates outputs and can retry with different parameters

---

## ğŸ“š Key Concepts

### RAG (Retrieval-Augmented Generation)
A technique that enhances language models by retrieving relevant information from external knowledge sources before generation. In this case, we retrieve similar translation examples from `economic v1.csv`.

### Vector Database
A specialized database that stores high-dimensional vectors (embeddings) and enables fast similarity search. Our economic corpus is embedded and indexed here.

### Semantic Search
Finding similar texts based on meaning rather than exact word matches. Powered by sentence embeddings.

### Few-Shot Learning
Providing the model with examples (from retrieved context) to guide translation, improving domain-specific accuracy.

---

## ğŸ“ Citation

If you use this system in research, please cite:

```bibtex
@software{rag_translation_agent,
  title={RAG Translation Agent: Context-Specific Machine Translation to Arabic},
  author={Your Name},
  year={2024},
  url={https://github.com/yourusername/your-repo}
}
```

---

## ğŸ“ License

This project is licensed under the MIT License. The UN parallel corpus (`economic v1.csv`) may have separate licensing terms.

---

## ğŸ¤ Contributing

Contributions are welcome! Areas for improvement:

- Additional translation models
- More evaluation metrics
- Domain expansion beyond economics
- Multi-language support
- Fine-tuning scripts

---

## ğŸ“ Support

For issues, questions, or suggestions:
- Open an issue on GitHub
- Check the troubleshooting section
- Review example scripts

---

## ğŸ“‚ Complete File Structure

```
RAG_Agent/
â”œâ”€â”€ ğŸ“„ README.md              â† You are here! Complete documentation
â”‚
â”œâ”€â”€ ğŸ”§ Core Components
â”‚   â”œâ”€â”€ rag_agent.py          â† RAG orchestrator (agentic logic)
â”‚   â”œâ”€â”€ vector_db.py          â† Vector database manager
â”‚   â””â”€â”€ utils.py              â† Helper functions
â”‚
â”œâ”€â”€ ğŸ› ï¸ Scripts & Tools
â”‚   â”œâ”€â”€ build_vector_db.py    â† Build vector DB from economic v1.csv
â”‚   â”œâ”€â”€ evaluate.py           â† Evaluation suite
â”‚   â”œâ”€â”€ app.py                â† Streamlit web interface
â”‚   â”œâ”€â”€ example.py            â† Usage examples
â”‚   â””â”€â”€ check_gpu.py          â† GPU diagnostics
â”‚
â”œâ”€â”€ ğŸ“Š Data
â”‚   â””â”€â”€ economic v1.csv       â† UN parallel corpus (EN-AR)
â”‚
â”œâ”€â”€ âš™ï¸ Configuration
â”‚   â”œâ”€â”€ config.ini            â† System configuration
â”‚   â”œâ”€â”€ requirements.txt      â† Python dependencies
â”‚   â”œâ”€â”€ setup.fish            â† Setup script (Fish shell)
â”‚   â””â”€â”€ setup.sh              â† Setup script (Bash)
â”‚
â””â”€â”€ ğŸ—‚ï¸ Generated (after setup)
    â”œâ”€â”€ vector_db/            â† Vector database storage
    â”œâ”€â”€ logs/                 â† Application logs
    â””â”€â”€ venv/                 â† Python virtual environment
```

---

## ğŸ‰ Summary

You now have a complete RAG-based translation system that:

âœ… Uses `economic v1.csv` as knowledge base  
âœ… Performs semantic retrieval for context  
âœ… Acts as an intelligent agent with autonomous decision-making  
âœ… Delivers domain-specific, consistent translations  
âœ… Supports multiple models and configurations  
âœ… Provides web UI and Python API  
âœ… Includes comprehensive evaluation tools  
âœ… Offers GPU acceleration for performance  

**Ready to translate!** ğŸš€

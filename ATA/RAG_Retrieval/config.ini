# RAG Agent Configuration

[GENERAL]
project_name = Context-Specific Translation RAG
data_dir = ./data
output_dir = ./outputs
logs_dir = ./logs
vector_db_dir = ./vector_db

[DATA]
# Path to your UN parallel corpora
corpus_file = ./economic v1.csv
# Expected columns in CSV
source_column = en
target_column = ar
domain_column = domain
# Data split ratios
train_ratio = 0.8
val_ratio = 0.1
test_ratio = 0.1

[EMBEDDINGS]
# Multilingual embedding model for semantic search
# Options: sentence-transformers/paraphrase-multilingual-mpnet-base-v2
#          sentence-transformers/LaBSE
#          intfloat/multilingual-e5-large
model_name = sentence-transformers/paraphrase-multilingual-mpnet-base-v2
embedding_dim = 768
# Reduced for low VRAM GPU (RTX 2050 with 3.7GB)
batch_size = 16
device = cuda

[VECTOR_DB]
# Vector database type: chromadb or faiss
# FAISS GPU-accelerated for better performance
db_type = faiss
collection_name = translation_corpus
# Distance metric: cosine, l2, ip (inner product)
distance_metric = cosine
# Number of results to retrieve
# Reduced for faster processing with limited VRAM
top_k = 3
# Minimum similarity threshold (0-1 for cosine)
similarity_threshold = 0.5

[TRANSLATION]
# Local Llama model for translation (optimized for 3.6GB VRAM)
# Options:
#   - meta-llama/Llama-2-7b-chat-hf (requires HuggingFace token)
#   - mistralai/Mistral-7B-Instruct-v0.2 (better for multilingual)
#   - HuggingFaceH4/zephyr-7b-beta (good alternative)
# Or use your fine-tuned QWEN model:
#   - ../LLMs/QWEN/outputs/technology_final
model_name = mistralai/Mistral-7B-Instruct-v0.2
device = cuda
use_8bit = false
# CRITICAL: Enable 4-bit quantization for 3.6GB VRAM
use_4bit = true
# Reduced for memory efficiency with quantized model
max_length = 256
temperature = 0.3
top_p = 0.9
# Not applicable for LLM generation (use top_p instead)
num_beams = 1

[RAG]
# RAG strategy
use_context_in_prompt = true
context_window = 3
# Whether to include source and target in context
include_source_in_context = true
include_target_in_context = true
# Prompt template (use \n for newlines in INI files)
prompt_template = You are a professional translator specializing in financial and economic texts.\n\nGiven the following similar translation examples:\n{context}\n\nNow translate the following English text to Arabic:\nEnglish: {source_text}\nArabic:

[EVALUATION]
# Metrics to compute
compute_bleu = true
compute_chrf = true
compute_ter = false
# Reference file for evaluation
test_file = ./data/test.csv

[API]
host = 0.0.0.0
port = 8000
debug = false

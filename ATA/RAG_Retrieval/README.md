# RAG Translation Agent - Context-Specific Machine Translation to Arabic<<<<<<< HEAD

# RAG Translation Agent - Context-Specific Machine Translation to Arabic

A Retrieval-Augmented Generation (RAG) system for English-to-Arabic translation using **local Mistral-7B-Instruct** with context-aware translation. Optimized for 3.6GB VRAM using 4-bit quantization.

A Retrieval-Augmented Generation (RAG) system for English-to-Arabic translation using **local Mistral-7B-Instruct** with context-aware translation.

---

## ğŸ¯ Project Overview

## ğŸ¯ Overview## ğŸ¯ What is This?

This project implements a **Retrieval-Augmented Generation (RAG)** system for context-aware English-to-Arabic translation, specifically optimized for economic and financial domain texts. The system combines semantic search with neural machine translation to deliver domain-specific, consistent, and accurate translations.

This project implements a **RAG-based translation system** that combines:



- **Vector Database (FAISS)** - Stores translation examples from economic/financial domain

- **Sentence Embeddings** - Semantic similarity search to find relevant contextThis system combines:### What Makes This "Agentic"?

- **Local Mistral-7B-Instruct** - 4-bit quantized LLM for high-quality translation

- **RAG Pipeline** - Retrieves similar examples to improve translation accuracy- **Vector Database** (FAISS) with 1.8M+ economic translation pairs



### Key Features- **Sentence Embeddings** for semantic similarity searchThe **agentic** nature of this system lies in its autonomous decision-making and multi-step reasoning process:



âœ… **100% Local** - No API keys, runs entirely on your machine  - **Google Gemini API** for context-aware translation

âœ… **Memory Efficient** - 4-bit quantization fits in 3.6GB VRAM  

âœ… **Context-Aware** - Uses similar translations to improve quality  - **RAG Pipeline** that retrieves similar examples to improve translation quality1. **Autonomous Context Retrieval**: The agent independently determines which translation examples are most relevant by:

âœ… **Evaluation Ready** - Built-in BLEU and chrF metrics  

âœ… **Domain-Specific** - Optimized for economic/financial texts     - Semantically analyzing the input text



---## ğŸš€ Quick Start   - Querying the vector database for similar examples



## ğŸš€ Quick Start   - Ranking and selecting the most contextually appropriate examples



### 1. Installation### 1. Installation



```bash2. **Adaptive Translation Strategy**: Based on retrieved context, the agent:

cd ATA/RAG_Retrieval

```bash   - Dynamically adjusts its translation approach

# Install dependencies

pip install -r requirements.txt# Install dependencies   - Incorporates domain-specific terminology

```

pip install -r requirements.txt   - Maintains consistency with similar past translations

**What gets installed:**

- PyTorch with CUDA support```

- Transformers + BitsAndBytes (4-bit quantization)

- Sentence transformers (embeddings)3. **Multi-Step Pipeline Orchestration**: The agent autonomously coordinates:

- FAISS (vector database)

- sacrebleu (evaluation metrics)### 2. Get Gemini API Key   - Text normalization and preprocessing



### 2. Build Vector Database   - Semantic retrieval operations



```bash1. Visit: https://makersuite.google.com/app/apikey   - Context formatting and prompt construction

# Index 10,000 translation examples (recommended for testing)

python build_vector_db.py --sample 100002. Create a free API key   - Translation generation with appropriate parameters



# Or use all available data:3. Set environment variable:   - Post-processing and result validation

# python build_vector_db.py

```



**Expected time:** 2-5 minutes  ```bash4. **Self-Optimization**: The system can:

**Output:** Vector database in `./vector_db/`

export GOOGLE_API_KEY="your_api_key_here"   - Filter results based on domain metadata

### 3. Test Translation

```   - Adjust retrieval parameters (top-k, similarity thresholds)

```bash

python test_translation.py   - Select between different translation models

```

### 3. Build Vector Database (First Time Only)   - Apply quantization strategies based on available resources

**What it does:**

- Loads vector database with translation examples

- Downloads & quantizes Mistral-7B (first run only, ~13GB)

- Translates test sentences WITH and WITHOUT RAG context```bashThis goes beyond a simple translation API by acting as an intelligent agent that makes contextual decisions at each step to optimize translation quality.

- Shows retrieved examples and improvements

python build_vector_db.py --config config.ini --sample 10000

**First run:** 60-90 seconds (model download)  

**Subsequent runs:** 10-20 seconds```---



### 4. Launch Web Interface



```bashThis indexes translation examples from `economic v1.csv` for retrieval.## ğŸ“Š Data Source

streamlit run app.py

```



Open browser at `http://localhost:8501` for interactive translation!### 4. Test Translation### Economic v1.csv - UN Parallel Corpus



---



## ğŸ“Š Model Configuration```bashThe system is trained and retrieves context from `economic v1.csv`, a parallel corpus containing:



### Current Model: **Mistral-7B-Instruct-v0.2**python test_gemini.py



Configured in `config.ini`:```- **Source**: English text from UN documents (economic and financial domain)



```ini- **Target**: Professional Arabic translations

[TRANSLATION]

model_name = mistralai/Mistral-7B-Instruct-v0.2### 5. Run Evaluation- **Size**: Contains thousands of parallel sentence pairs

device = cuda

use_4bit = true          # Critical for 3.6GB VRAM- **Domain**: Economic, financial, legal, and political terminology

max_length = 256

temperature = 0.3        # Low = deterministic, high = creative```bash- **Structure**:

top_p = 0.9

```# Extract test samples  - `id`: Unique identifier for each translation pair



### Alternative Modelspython extract_test_samples.py --num_samples 100  - `en`: English source text



You can change the model by editing `config.ini`:  - `ar`: Arabic target translation



```ini# Compare RAG vs non-RAG

# Option 1: Llama-2 (requires HuggingFace token)

model_name = meta-llama/Llama-2-7b-chat-hfpython compare_rag.py \**Example entries**:



# Option 2: Zephyr (good alternative)    --api_key $GOOGLE_API_KEY \```csv

model_name = HuggingFaceH4/zephyr-7b-beta

    --test_file test_samples.csv \id,en,ar

# Option 3: Your fine-tuned model

model_name = ../LLMs/QWEN/outputs/your_model    --sample 1001,"The question of financial assistance to defendants unable to fund their defence...","ÙˆÙ‡Ù†Ø§Ùƒ Ø­Ø§Ø¬Ø© Ø£ÙŠØ¶Ø§ Ø§Ù„Ù‰ Ø§Ù„Ù†Ø¸Ø± ÙÙŠ Ù…Ø³Ø£Ù„Ø© ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø§Ù„ÙŠØ©..."

```

```9,"It is estimated that the cost of maintaining UNFICYP...","ØªØ´ÙŠØ± Ø§Ù„ØªÙ‚Ø¯ÙŠØ±Ø§Øª Ø§Ù„Ù‰ Ø£Ù† ØªÙƒØ§Ù„ÙŠÙ Ø§ï»¹Ø¨Ù‚Ø§Ø¡ Ø¹Ù„Ù‰ Ù‚ÙˆØ©..."

**For Llama-2:** Run `huggingface-cli login` first

```

---

## ğŸ“Š How It Works

## ğŸ§ª Evaluation & Comparison

This high-quality parallel corpus serves as:

### Create Test Dataset

### RAG Translation Pipeline1. **Training data** for building the vector database

```bash

python extract_test_samples.py --num_samples 100 --output test_data.csv2. **Retrieval source** for finding similar translation contexts

```

```3. **Quality reference** for domain-specific terminology

### Compare RAG vs Non-RAG

Input Text

```bash

python compare_rag.py \    â†“---

    --test_file test_data.csv \

    --sample 50 \1. Normalize & Preprocess

    --output_dir ./evaluation_results \

    --top_k 3    â†“## ğŸ—ï¸ System Architecture

```

2. Generate Embedding (Sentence-BERT)

**What this does:**

1. Translates all samples **without RAG** (baseline)    â†“```

2. Translates same samples **with RAG** (context-aware)

3. Calculates BLEU and chrF scores3. Search Vector DB (FAISS)â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

4. Shows improvement metrics

5. Saves detailed results    â†“â”‚                         User Interface Layer                      â”‚



**Expected Output:**4. Retrieve Top-K Similar Examplesâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚



```    â†“â”‚  â”‚  Streamlit UI  â”‚  â”‚   Python API   â”‚  â”‚  CLI Scripts      â”‚ â”‚

ğŸ“Š RESULTS COMPARISON

============================================================5. Build Context Prompt with Examplesâ”‚  â”‚   (app.py)     â”‚  â”‚ (rag_agent.py) â”‚  â”‚ (example.py)      â”‚ â”‚



ğŸ”µ WITHOUT RAG (Baseline):    â†“â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚

   BLEU Score:  28.45

   chrF Score:  52.306. Send to Gemini APIâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   Successful:  50/50

    â†“                              â†“

ğŸŸ¢ WITH RAG (Context-Aware):

   BLEU Score:  34.787. Get Context-Aware Translationâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

   chrF Score:  58.92

   Successful:  50/50    â†“â”‚                     RAG Agent (Orchestrator)                      â”‚



ğŸ“ˆ IMPROVEMENT:Output Translationâ”‚                         rag_agent.py                              â”‚

   BLEU: +6.33 points (+22.3%)

   chrF: +6.62 points (+12.7%)```â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚

```

â”‚  â”‚  1. Text Normalization                                    â”‚  â”‚

**Results saved to:**

- `evaluation_results/comparison_summary_*.json` - Metrics### Exampleâ”‚  â”‚  2. Context Retrieval (semantic search)                   â”‚  â”‚

- `evaluation_results/detailed_translations_*.csv` - All translations

â”‚  â”‚  3. Prompt Construction (with retrieved examples)         â”‚  â”‚

---

**Without RAG (Baseline)**:â”‚  â”‚  4. Translation Generation                                â”‚  â”‚

## ğŸ“ Project Structure

```â”‚  â”‚  5. Result Post-processing                                â”‚  â”‚

```

RAG_Retrieval/Input: "The economic growth rate increased significantly."â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚

â”œâ”€â”€ rag_agent.py              # Core translation agent (Mistral-7B)

â”œâ”€â”€ vector_db.py              # Vector database manager (FAISS)Output: [Generic translation]â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”œâ”€â”€ utils.py                  # Utility functions

â”œâ”€â”€ config.ini                # Configuration file```              â†“                                â†“

â”œâ”€â”€ requirements.txt          # Dependencies

â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”œâ”€â”€ compare_rag.py            # â­ RAG evaluation script

â”œâ”€â”€ evaluate.py               # General evaluation**With RAG (Context-Aware)**:â”‚   Retrieval Component      â”‚    â”‚   Translation Component      â”‚

â”œâ”€â”€ test_translation.py       # Quick functionality test

â”œâ”€â”€ quick_test.py             # Minimal test```â”‚     vector_db.py           â”‚    â”‚      Transformers            â”‚

â”œâ”€â”€ example.py                # Usage examples

â”‚Input: "The economic growth rate increased significantly."â”‚                            â”‚    â”‚                              â”‚

â”œâ”€â”€ app.py                    # Streamlit web interface

â”œâ”€â”€ build_vector_db.py        # Build FAISS indexâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚

â”œâ”€â”€ extract_test_samples.py   # Create test datasets

â”‚Retrieved Examples:â”‚  â”‚ Embedding Model      â”‚ â”‚    â”‚  â”‚ Translation Models     â”‚ â”‚

â”œâ”€â”€ economic v1.csv           # Training corpus (UN data)

â””â”€â”€ vector_db/                # FAISS index (created after build)1. "Economic indicators show positive trends" â†’ "ØªØ¸Ù‡Ø± Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ© Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©"â”‚  â”‚ â€¢ Sentence-BERT      â”‚ â”‚    â”‚  â”‚ â€¢ MarianMT (default)   â”‚ â”‚

```

2. "The growth rate exceeds expectations" â†’ "Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù…Ùˆ ÙŠØªØ¬Ø§ÙˆØ² Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª"â”‚  â”‚ â€¢ Multilingual       â”‚ â”‚    â”‚  â”‚ â€¢ NLLB                 â”‚ â”‚

---

3. "GDP growth accelerated" â†’ "ØªØ³Ø§Ø±Ø¹ Ù†Ù…Ùˆ Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ"â”‚  â”‚ â€¢ 768D vectors       â”‚ â”‚    â”‚  â”‚ â€¢ QWEN (fine-tuned)    â”‚ â”‚

## ğŸ“ How RAG Works

â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚

### Without RAG (Baseline)

```Output: [Domain-specific, consistent translation using economic terminology]â”‚                            â”‚    â”‚                              â”‚

English Text â†’ Mistral-7B â†’ Arabic Translation

``````â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚



Simple, but lacks domain knowledge and consistency.â”‚  â”‚ Vector Database      â”‚ â”‚    â”‚  â”‚ Generation Config      â”‚ â”‚



### With RAG (Context-Aware)## ğŸ“ File Structureâ”‚  â”‚ â€¢ ChromaDB           â”‚ â”‚    â”‚  â”‚ â€¢ Beam search          â”‚ â”‚

```

English Text â†’ Vector DB Search â†’ Similar Examplesâ”‚  â”‚ â€¢ FAISS (GPU-accel.) â”‚ â”‚    â”‚  â”‚ â€¢ Temperature tuning   â”‚ â”‚

              â†“

    [Example 1, Example 2, Example 3]```â”‚  â”‚ â€¢ Cosine similarity  â”‚ â”‚    â”‚  â”‚ â€¢ Top-p sampling       â”‚ â”‚

              â†“

       Mistral-7B (with context) â†’ Arabic TranslationRAG_Agent/â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚

```

â”œâ”€â”€ rag_agent.py              # Main translation agent (Gemini API)â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

The model sees similar translations and adapts accordingly!

â”œâ”€â”€ vector_db.py              # FAISS vector database manager              â†“

### Example

â”œâ”€â”€ utils.py                  # Utilities (normalization, formatting)â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

**Input:** "The economic growth rate increased significantly."

â”œâ”€â”€ config.ini                # Configuration settingsâ”‚                      Data Storage Layer                           â”‚

**Retrieved Context:**

1. "Economic growth accelerated..." â†’ "ØªØ³Ø§Ø±Ø¹ Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ..."â”‚â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚

2. "The GDP growth rate rose..." â†’ "Ø§Ø±ØªÙØ¹ Ù…Ø¹Ø¯Ù„ Ù†Ù…Ùˆ Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù…Ø­Ù„ÙŠ..."

3. "Significant increase in growth..." â†’ "Ø²ÙŠØ§Ø¯Ø© ÙƒØ¨ÙŠØ±Ø© ÙÙŠ Ø§Ù„Ù†Ù…Ùˆ..."â”œâ”€â”€ build_vector_db.py        # Build/update vector databaseâ”‚  â”‚  Vector Index   â”‚  â”‚  Metadata Store  â”‚  â”‚  Economic Data â”‚ â”‚



**Result:** More accurate terminology and natural phrasing!â”œâ”€â”€ test_gemini.py            # Quick test scriptâ”‚  â”‚  (embeddings)   â”‚  â”‚   (text pairs)   â”‚  â”‚ (economic.csv) â”‚ â”‚



---â”œâ”€â”€ compare_rag.py            # Evaluation with metrics (BLEU, chrF)â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚



## ğŸ“ˆ Performance Expectationsâ”œâ”€â”€ extract_test_samples.py   # Extract test dataâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜



### VRAM Usageâ”‚```

- **Embeddings model:** ~0.5 GB

- **Mistral-7B (4-bit):** ~3.5-4 GBâ”œâ”€â”€ app.py                    # Streamlit web UI (optional)

- **Total:** ~4-4.5 GB

- **Recommended:** 6GB+ VRAMâ”œâ”€â”€ evaluate.py               # Full evaluation suite---



### Translation Speedâ”œâ”€â”€ requirements.txt          # Python dependencies

- **First translation:** 30-60 seconds (model loading)

- **With RAG:** 2-5 seconds/sentenceâ”‚## ğŸ”„ RAG Process Explained

- **Without RAG:** 1-3 seconds/sentence

â”œâ”€â”€ economic v1.csv           # Translation corpus (1.8M pairs)

### Quality Improvements

- **BLEU:** +15-30% improvementâ””â”€â”€ vector_db/                # FAISS index files### Step-by-Step Translation Pipeline

- **chrF:** +10-20% improvement

- **Consistency:** Significantly better    â””â”€â”€ translation_corpus.index

- **Domain accuracy:** Much improved

```#### 1. **Input Processing** (`utils.py`)

---

```

## âš™ï¸ Configuration Guide

## ğŸ”§ ConfigurationUser Input: "The GDP growth rate increased by 3.5% in Q2 2024"

Edit `config.ini` to customize:

                    â†“

### Vector Database

```iniEdit `config.ini`:        [Text Normalization]

[VECTOR_DB]

db_type = faiss              # GPU-accelerated                    â†“

top_k = 3                    # Number of examples to retrieve

similarity_threshold = 0.5   # Minimum similarity (0-1)```iniNormalized: "The GDP growth rate increased by 3.5% in Q2 2024"

```

[GEMINI]```

### Embeddings

```inimodel_name = gemini-pro

[EMBEDDINGS]

model_name = sentence-transformers/paraphrase-multilingual-mpnet-base-v2temperature = 0.3#### 2. **Semantic Embedding** (`vector_db.py`)

device = cuda

batch_size = 16top_k_retrieval = 3```

```

max_output_tokens = 512Normalized Text â†’ Sentence-BERT Encoder â†’ 768D Vector

### Translation Model

```ini[0.023, -0.145, 0.892, ..., 0.334]

[TRANSLATION]

model_name = mistralai/Mistral-7B-Instruct-v0.2[VECTOR_DB]```

use_4bit = true              # CRITICAL for low VRAM

max_length = 256             # Output length limitdb_type = faiss

temperature = 0.3            # 0.1 = deterministic, 1.0 = creative

top_p = 0.9                  # Nucleus samplingcollection_name = translation_corpus#### 3. **Context Retrieval** (`vector_db.py`)

```

The vector database searches for similar translation examples:

---

[EMBEDDINGS]```

## ğŸ’¡ Usage Examples

model_name = sentence-transformers/paraphrase-multilingual-mpnet-base-v2Query Vector â†’ Vector Database (FAISS/ChromaDB)

### Basic Translation

device = cuda                    â†“

```python

from rag_agent import RAGTranslationAgent```    [Cosine Similarity Search]

from vector_db import VectorDBManager

from utils import load_config                    â†“



# Load configuration## ğŸ’» UsageTop-5 Similar Examples (from economic v1.csv):

config = load_config("config.ini")

1. "The economic growth rate increased..." â†’ "Ø§Ø±ØªÙØ¹ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ..."

# Initialize vector database

vector_db = VectorDBManager(### Python API2. "GDP estimates for the quarter..." â†’ "ØªÙ‚Ø¯ÙŠØ±Ø§Øª Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù„Ù„Ø±Ø¨Ø¹..."

    db_type="faiss",

    embedding_model=config.get("EMBEDDINGS", "model_name"),3. "Growth statistics show..." â†’ "ØªØ¸Ù‡Ø± Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø§Ù„Ù†Ù…Ùˆ..."

    db_path="./vector_db",

    collection_name="translation_corpus",```python4. "Financial indicators improved..." â†’ "ØªØ­Ø³Ù†Øª Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©..."

    device="cuda"

)from rag_agent import RAGTranslationAgent5. "The rate of increase..." â†’ "Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø²ÙŠØ§Ø¯Ø©..."



# Initialize translation agentfrom vector_db import VectorDBManager```

agent = RAGTranslationAgent(

    model_name="mistralai/Mistral-7B-Instruct-v0.2",from utils import load_config

    vector_db_manager=vector_db,

    device="cuda",#### 4. **Prompt Construction** (`rag_agent.py`)

    use_4bit=True,

    temperature=0.3,# Load config```

    top_k_retrieval=3

)config = load_config("config.ini")System: You are a professional translator specializing in economic texts.



# Translate with RAG

result = agent.translate(

    "The economic growth rate increased significantly.",# Initialize vector databaseContext (Similar Examples):

    use_context=True,

    return_context=Truevector_db = VectorDBManager(- EN: "The economic growth rate increased..."

)

    db_type="faiss",  AR: "Ø§Ø±ØªÙØ¹ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ..."

print(f"Translation: {result['translation']}")

print(f"Used {result['num_retrieved']} examples")    embedding_model=config.get("EMBEDDINGS", "model_name"),- EN: "GDP estimates for the quarter..."



# Show retrieved examples    db_path="./vector_db",  AR: "ØªÙ‚Ø¯ÙŠØ±Ø§Øª Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù„Ù„Ø±Ø¨Ø¹..."

for i, ex in enumerate(result['retrieved_examples'], 1):

    print(f"\nExample {i} (similarity: {ex['similarity']:.3f}):")    device="cuda"[... more examples ...]

    print(f"  EN: {ex['en']}")

    print(f"  AR: {ex['ar']}"))

```

Now translate:

### Translation Without RAG

# Initialize translation agentEN: "The GDP growth rate increased by 3.5% in Q2 2024"

```python

# Baseline translation (no context)agent = RAGTranslationAgent(AR: 

result = agent.translate(

    "The economic growth rate increased significantly.",    api_key="YOUR_GEMINI_API_KEY",  # or use env var```

    use_context=False

)    vector_db_manager=vector_db,



print(f"Translation: {result['translation']}")    model_name="gemini-pro",#### 5. **Translation Generation** (`rag_agent.py`)

```

    temperature=0.3,```

### Batch Translation

    top_k_retrieval=3Prompt â†’ Translation Model (MarianMT/NLLB/QWEN)

```python

sentences = [)                    â†“

    "The economic growth rate increased.",

    "Inflation remains a concern.",        [Beam Search Decoding]

    "The central bank announced new policies."

]# Translate with RAG        [Context-Aware Generation]



results = agent.batch_translate(result = agent.translate(                    â†“

    sentences,

    use_context=True    "The economic growth rate increased significantly.",Arabic Translation: "Ø§Ø±ØªÙØ¹ Ù…Ø¹Ø¯Ù„ Ù†Ù…Ùˆ Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¨Ù†Ø³Ø¨Ø© 3.5% ÙÙŠ Ø§Ù„Ø±Ø¨Ø¹ Ø§Ù„Ø«Ø§Ù†ÙŠ Ù…Ù† Ø¹Ø§Ù… 2024"

)

    use_context=True,```

for i, result in enumerate(results):

    print(f"{i+1}. {result['translation']}")    return_context=True

```

)#### 6. **Post-Processing** (`utils.py`)

---

```

## ğŸ“Š Understanding Metrics

print(f"Translation: {result['translation']}")Raw Output â†’ [Normalization] â†’ Final Translation

### BLEU Score (0-100)

- Measures n-gram overlap with reference translationprint(f"Used {result['num_retrieved']} context examples")```

- Industry standard for machine translation

- **20-30:** Understandable```

- **30-40:** Good quality

- **40-50:** Very good### Why RAG Improves Translation

- **50+:** Excellent

### Command Line

**RAG typically adds +5 to +15 points**

**Without RAG** (baseline model):

### chrF Score (0-100)

- Character-level F-score```bash```

- Better for morphologically rich languages (Arabic)

- More robust than BLEU# Quick testInput: "The GDP growth rate increased by 3.5%"

- Generally higher scores

python test_gemini.pyOutput: "Ø²Ø§Ø¯ Ù…Ø¹Ø¯Ù„ Ù†Ù…Ùˆ Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø¨Ù†Ø³Ø¨Ø© 3.5Ùª"

**RAG typically adds +3 to +10 points**

        (Generic translation, inconsistent terminology)

### What Good Results Look Like

- âœ… BLEU improvement > 5 points# Full evaluation```

- âœ… chrF improvement > 3 points

- âœ… Consistent domain terminologypython compare_rag.py --api_key $GOOGLE_API_KEY --test_file test.csv

- âœ… Natural, fluent translations

**With RAG** (context-aware):

---

# Web UI```

## ğŸ› Troubleshooting

streamlit run app.pyInput: "The GDP growth rate increased by 3.5%"

### Out of Memory Error

```Retrieved Context: Similar economic translations from UN corpus

```

RuntimeError: CUDA out of memoryOutput: "Ø§Ø±ØªÙØ¹ Ù…Ø¹Ø¯Ù„ Ù†Ù…Ùˆ Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¨Ù†Ø³Ø¨Ø© 3.5Ùª"

```

## ğŸ“ˆ Evaluation Metrics        (Domain-specific, consistent with UN terminology)

**Solutions:**

1. Ensure `use_4bit = true` in config.ini```

2. Close other GPU applications

3. Reduce `max_length` to 128The system evaluates translation quality using:

4. Try a smaller model or reduce `batch_size`

---

### Model Download Issues

- **BLEU Score**: Precision-based metric (0-100)

```

HTTPError: 401 Unauthorized- **chrF Score**: Character n-gram F-score (0-100)## ğŸ“ File Structure and Purpose

```



For Llama-2, get a HuggingFace token:

```bash### Expected Results### Core Components

huggingface-cli login

```



Or use Mistral (no token needed):```#### 1. **`rag_agent.py`** - The Orchestrator

```ini

model_name = mistralai/Mistral-7B-Instruct-v0.2ğŸ“Š RESULTS COMPARISON**Purpose**: Main agentic component that coordinates the entire RAG pipeline.

```

============================================================

### Slow First Run

**Key Responsibilities**:

The first run downloads ~13GB model - this is normal and only happens once.

ğŸ”µ WITHOUT RAG (Baseline):- Manages the translation workflow

### Poor Translation Quality

   BLEU Score:  42.35- Coordinates retrieval and generation

Try adjusting in `config.ini`:

```ini   chrF Score:  65.78- Handles different model types (Seq2Seq, Causal LM)

# More deterministic

temperature = 0.1- Implements context-aware prompting



# Retrieve more examplesğŸŸ¢ WITH RAG (Context-Aware):- Batch processing support

top_k = 5

   BLEU Score:  58.92

# Higher similarity threshold

similarity_threshold = 0.6   chrF Score:  78.43**Key Class**: `RAGTranslationAgent`

```

- **Methods**:

---

ğŸ“ˆ IMPROVEMENT:  - `translate()`: Single text translation with RAG

## ğŸ¯ Quick Command Reference

   BLEU: +16.57 points (+39.1%)  - `translate_batch()`: Batch translation processing

| Task | Command |

|------|---------|   chrF: +12.65 points (+19.2%)  - `_translate_seq2seq()`: For MarianMT, NLLB models

| Install | `pip install -r requirements.txt` |

| Build database | `python build_vector_db.py --sample 10000` |```  - `_translate_causal()`: For QWEN, LLaMA models

| Quick test | `python test_translation.py` |

| Create test data | `python extract_test_samples.py --num_samples 100` |

| **Run evaluation** | `python compare_rag.py --test_file test_data.csv --sample 50` |

| Web interface | `streamlit run app.py` |## ğŸ“ Key Features**Agentic Features**:

| Check GPU | `nvidia-smi` |

- Autonomous context retrieval decisions

---

### Why RAG?- Dynamic prompt construction based on retrieved examples

## ğŸ“š Data Source

- Adaptive generation parameters

### Economic v1.csv - UN Parallel Corpus

1. **Domain Adaptation**: Uses economic/financial terminology from corpus

The system uses a parallel corpus containing:

2. **Consistency**: Learns translation style from retrieved examples#### 2. **`vector_db.py`** - The Memory System

- **Source:** English text from UN documents

- **Target:** Professional Arabic translations  3. **Context-Aware**: Better handling of idiomatic expressions**Purpose**: Manages semantic search and retrieval from the parallel corpus.

- **Domain:** Economic, financial, legal, and political terminology

- **Size:** Thousands of high-quality parallel sentence pairs4. **Dynamic**: No model retraining needed for new domains



**Structure:****Key Responsibilities**:

- `en` - English source text

- `ar` - Arabic target translation### Why Gemini API?- Build vector database from `economic v1.csv`

- `domain` - Document domain/category (optional)

- Generate embeddings for source texts

---

1. **Causal Language Model**: Excels at in-context learning- Perform semantic similarity search

## ğŸ”¬ System Requirements

2. **Few-Shot Learning**: Effectively uses retrieved examples- Handle both ChromaDB and FAISS backends

### Hardware

- **GPU:** 6GB+ VRAM (4GB might work but tight)3. **Easy Setup**: No local GPU requirements

- **RAM:** 16GB+ system RAM

- **Storage:** ~15GB for models and database4. **Free Tier**: 60 requests/min, 1,500/day**Key Class**: `VectorDBManager`



### Software- **Methods**:

- **CUDA:** 11.8+ or 12.x

- **Python:** 3.8+## ğŸ” Comparison with MarianMT  - `build_from_dataframe()`: Index the economic corpus

- **OS:** Linux (tested), Windows/Mac should work

  - `retrieve()`: Semantic search for similar translations

---

| Feature | MarianMT (Previous) | Gemini + RAG (Current) |  - `add_examples()`: Add new translation pairs

## ğŸš¦ Getting Started Checklist

|---------|---------------------|------------------------|  - `_initialize_chromadb()` / `_initialize_faiss()`: Backend setup

- [ ] Install dependencies: `pip install -r requirements.txt`

- [ ] Build vector database: `python build_vector_db.py --sample 10000`| **Architecture** | Seq2Seq Encoder-Decoder | Causal Language Model |

- [ ] Test system: `python test_translation.py`

- [ ] Extract test data: `python extract_test_samples.py --num_samples 100`| **Context Usage** | âŒ Can't use retrieved examples | âœ… Leverages RAG context |**Supported Backends**:

- [ ] Run evaluation: `python compare_rag.py --test_file test_data.csv --sample 50`

- [ ] Check results in `evaluation_results/`| **Domain Adaptation** | âŒ Fixed at training | âœ… Dynamic via retrieval |- **ChromaDB**: Easy persistence, good for <10M documents

- [ ] Try web interface: `streamlit run app.py`

| **Setup** | Complex (quantization issues) | Simple (API key) |- **FAISS**: Ultra-fast search, GPU-accelerated, scalable

---

| **Hardware** | Requires GPU | API-based (no GPU needed) |

## ğŸ“ Next Steps

| **Translation Quality** | Good | Better with context |#### 3. **`utils.py`** - Helper Functions

1. **Run comparison** to see RAG improvements

2. **Tune parameters** in config.ini (temperature, top_k)**Purpose**: Common utilities for text processing and configuration.

3. **Add domain data** to vector database

4. **Fine-tune model** on your specific domain## ğŸ› Troubleshooting

5. **Deploy** to production

**Key Functions**:

---

### API Key Error- `normalize_english_text()`: Clean and normalize English input

## ğŸ“„ License

- `normalize_arabic_text()`: Clean and normalize Arabic output

This project is part of the Context-Specific Machine Translation research.

```bash- `format_context_examples()`: Format retrieved examples for prompts

---

# Check if set- `chunk_text()`: Handle long texts

## ğŸ¤ Contributing

echo $GOOGLE_API_KEY- `load_config()`: Configuration management

Contributions, issues, and feature requests are welcome!

- `setup_logging()`: Logging infrastructure

---

# Set it

**Built with â¤ï¸ for accurate, context-aware Arabic translation**

export GOOGLE_API_KEY="your_key_here"### Scripts and Tools

```

#### 4. **`build_vector_db.py`** - Database Builder

### Rate Limit Error**Purpose**: Process `economic v1.csv` and build the searchable vector database.



```python**Usage**:

# Add delay between requests```bash

import time# Build from economic corpus

time.sleep(1)  # 1 second = 60 req/minpython build_vector_db.py --config config.ini

```

# Test with sample

### Import Errorpython build_vector_db.py --sample 1000

```

```bash

# Reinstall package**What It Does**:

pip install --upgrade google-generativeai1. Reads `economic v1.csv` (EN-AR parallel sentences)

```2. Generates embeddings for English sentences

3. Creates vector index (ChromaDB or FAISS)

### Poor Translation Quality4. Stores metadata (EN text, AR translation, domains)

5. Saves to disk for retrieval

1. Increase `top_k_retrieval` (try 5-7)

2. Lower `temperature` (try 0.1-0.2)**Output**: Vector database in `./vector_db/` directory

3. Rebuild vector DB with more samples

#### 5. **`evaluate.py`** - Evaluation Suite

## ğŸ“Š Dataset**Purpose**: Measure translation quality with and without RAG.



**economic v1.csv**: 1,799,855 parallel EN-AR sentence pairs**Metrics**:

- Source: UN documents and economic reports- **BLEU**: N-gram overlap score (0-100)

- Domain: Economics, finance, international development- **chrF**: Character-level F-score (0-100)

- Format: CSV with columns: `id`, `en`, `ar`

**Usage**:

## ğŸš€ API Usage```bash

# Evaluate on test set

**Gemini API Free Tier:**python evaluate.py --config config.ini --test_file test_data.csv

- 60 requests per minute

- 1,500 requests per day# Compare RAG vs baseline

- Free foreverpython evaluate.py --compare_baseline

```

**For 100 test samples:**

- Baseline: 100 requests**Output**:

- RAG: 100 requests- Aggregate metrics (BLEU, chrF)

- **Total: 200 requests** (~3.5 minutes)- Per-example results

- RAG improvement statistics

## ğŸ“ License- Sample translations



This project uses:#### 6. **`app.py`** - Web Interface

- Google Gemini API (subject to Google's terms)**Purpose**: Interactive Streamlit demo for the translation system.

- Open-source dependencies (see requirements.txt)

**Features**:

## ğŸ¤ Contributing- Single text translation

- Batch translation (CSV upload)

To improve the system:- Context visualization (shows retrieved examples)

1. Tune hyperparameters in `config.ini`- Export results to CSV/JSON

2. Try different Gemini models (gemini-1.5-flash, etc.)- Real-time translation

3. Add domain-specific corpora to vector DB- Configuration options

4. Experiment with prompt templates

**Usage**:

## ğŸ“š References```bash

streamlit run app.py

- [Gemini API Documentation](https://ai.google.dev/docs)```

- [FAISS Documentation](https://github.com/facebookresearch/faiss)

- [Sentence-BERT](https://www.sbert.net/)**Interface Sections**:

- [RAG Paper](https://arxiv.org/abs/2005.11401)- Text input area

- Translation button

---- Results display (Arabic output)

- Retrieved context panel

âœ… **Ready to translate with context-aware RAG!**- Statistics and metrics



For questions or issues, check the logs in `./logs/` or review the configuration in `config.ini`.#### 7. **`example.py`** - Usage Examples

**Purpose**: Simple demonstrations and quick testing.

**Examples Included**:
- Basic translation
- Batch processing
- Custom configuration
- Error handling
- Performance testing

**Usage**:
```bash
python example.py
```

### Configuration

#### 8. **`config.ini`** - System Configuration
**Purpose**: Centralized configuration for all components.

**Key Sections**:

```ini
[GENERAL]
vector_db_dir = ./vector_db        # Where to store/load vector DB
logs_dir = ./logs                  # Logging directory
corpus_file = ./economic v1.csv    # Path to parallel corpus

[EMBEDDINGS]
model_name = sentence-transformers/paraphrase-multilingual-mpnet-base-v2
device = cuda                      # cuda, cpu, or mps
batch_size = 32                    # Embedding batch size

[VECTOR_DB]
db_type = faiss                    # chromadb or faiss
collection_name = translation_corpus
top_k = 5                          # Number of examples to retrieve

[TRANSLATION]
model_name = Helsinki-NLP/opus-mt-en-ar
device = cuda
max_length = 512
num_beams = 5                      # Beam search width
temperature = 0.7                  # Sampling temperature
top_p = 0.9                        # Nucleus sampling
use_4bit = false                   # 4-bit quantization
use_8bit = false                   # 8-bit quantization
```

#### 9. **`requirements.txt`** - Dependencies
**Purpose**: All Python package dependencies.

**Key Packages**:
```
torch>=2.0.0                       # PyTorch
transformers>=4.30.0               # HuggingFace models
sentence-transformers>=2.2.0       # Embedding models
chromadb>=0.4.0                    # ChromaDB backend
faiss-gpu>=1.7.2                   # FAISS GPU backend
streamlit>=1.25.0                  # Web UI
pandas>=1.5.0                      # Data processing
numpy>=1.24.0                      # Numerical operations
sacrebleu>=2.3.0                   # BLEU metric
```

### Setup Scripts

#### 10. **`setup.fish`** / **`setup.sh`** - Automated Setup
**Purpose**: One-command environment setup for Fish/Bash shells.

**What They Do**:
```bash
./setup.fish  # or ./setup.sh
```

1. Create Python virtual environment
2. Install all dependencies from `requirements.txt`
3. Verify GPU/CUDA setup
4. Create necessary directories
5. Check configuration

### Utility Scripts

#### 11. **`check_gpu.py`** - GPU Diagnostics
**Purpose**: Verify GPU/CUDA setup and provide recommendations.

**Usage**:
```bash
python check_gpu.py
```

**Checks**:
- PyTorch CUDA availability
- GPU device information
- VRAM availability
- FAISS GPU support
- Optimal configuration suggestions

---

## ğŸš€ Quick Start Guide

### Installation (2 minutes)

```bash
cd RAG_Agent

# Run automated setup
./setup.fish  # or ./setup.sh for bash

# Activate environment
source venv/bin/activate.fish
```

### Build Vector Database (5-10 minutes)

```bash
# Build from economic v1.csv
python build_vector_db.py --config config.ini

# Or test with sample first
python build_vector_db.py --sample 1000
```

This processes the `economic v1.csv` corpus and creates the vector index.

### Test the System (1 minute)

```bash
# Run example script
python example.py
```

### Launch Web Interface (30 seconds)

```bash
# Start Streamlit app
streamlit run app.py
```

Opens at `http://localhost:8501`

---

## ğŸ’» Usage Examples

### Python API - Basic Translation

```python
from rag_agent import RAGTranslationAgent
from vector_db import VectorDBManager

# Initialize vector database
vector_db = VectorDBManager(
    db_type="faiss",
    embedding_model="sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
    db_path="./vector_db"
)

# Initialize RAG agent
agent = RAGTranslationAgent(
    translation_model="Helsinki-NLP/opus-mt-en-ar",
    vector_db_manager=vector_db,
    top_k_retrieval=5
)

# Translate
result = agent.translate(
    "The economic growth rate increased by 3.5%",
    return_context=True
)

print(f"Translation: {result['translation']}")
print(f"Retrieved {len(result['context'])} examples")
```

### Batch Translation

```python
import pandas as pd

# Load test data
df = pd.read_csv("test_data.csv")

# Translate all English texts
results = agent.translate_batch(df['en'].tolist())

# Add translations to dataframe
df['ar_predicted'] = [r['translation'] for r in results]

# Save results
df.to_csv("translations_output.csv", index=False)
```

### Compare With/Without RAG

```python
# Translate with RAG (context-aware)
result_with_rag = agent.translate(
    "The GDP increased significantly",
    use_context=True
)

# Translate without RAG (baseline)
result_without_rag = agent.translate(
    "The GDP increased significantly",
    use_context=False
)

print("With RAG:", result_with_rag['translation'])
print("Without RAG:", result_without_rag['translation'])
```

---

## ğŸ“Š Evaluation

### Running Evaluation

```bash
# Evaluate on test set
python evaluate.py --test_file test_data.csv --config config.ini

# Compare RAG vs baseline
python evaluate.py --compare_baseline --output_file results.json
```

### Expected Results

**With RAG** (Context-Aware):
- BLEU: 45-55
- chrF: 65-75
- Better domain terminology
- More consistent translations

**Without RAG** (Baseline):
- BLEU: 35-45
- chrF: 55-65
- Generic translations
- Less consistent

---

## âš™ï¸ GPU/CUDA Support

### Check GPU Setup

```bash
python check_gpu.py
```

### GPU Configuration

For GPU acceleration, ensure `config.ini` has:

```ini
[EMBEDDINGS]
device = cuda

[TRANSLATION]
device = cuda
use_8bit = false  # Set true if <16GB VRAM
use_4bit = false  # Set true if <12GB VRAM
```

### FAISS GPU Acceleration

FAISS automatically uses GPU if available. Benefits:
- 10-20x faster retrieval
- Handles larger vector databases
- Reduced latency

---

## ğŸ”§ Customization

### Use Different Translation Models

```python
# Option 1: MarianMT (default, fast)
agent = RAGTranslationAgent(
    translation_model="Helsinki-NLP/opus-mt-en-ar",
    vector_db_manager=vector_db
)

# Option 2: NLLB (high quality, multilingual)
agent = RAGTranslationAgent(
    translation_model="facebook/nllb-200-distilled-600M",
    vector_db_manager=vector_db
)

# Option 3: Fine-tuned QWEN (best for domain)
agent = RAGTranslationAgent(
    translation_model="path/to/finetuned-qwen",
    vector_db_manager=vector_db
)
```

### Adjust Retrieval Parameters

```python
# More context examples
agent = RAGTranslationAgent(
    translation_model="Helsinki-NLP/opus-mt-en-ar",
    vector_db_manager=vector_db,
    top_k_retrieval=10  # Retrieve 10 examples instead of 5
)

# Domain-specific retrieval
result = agent.translate(
    "The GDP increased",
    domain="economic",  # Filter by domain
    top_k=7
)
```

### Custom Prompt Templates

```python
custom_prompt = """You are an expert economic translator.

Examples from UN corpus:
{context}

Translate this economic text to Arabic:
{source_text}

Translation:"""

agent = RAGTranslationAgent(
    translation_model="Helsinki-NLP/opus-mt-en-ar",
    vector_db_manager=vector_db,
    prompt_template=custom_prompt
)
```

---

## ğŸ› Troubleshooting

### Issue: "Vector database not found"

**Solution**: Build the database first:
```bash
python build_vector_db.py --config config.ini
```

### Issue: "CUDA out of memory"

**Solution**: Enable quantization in `config.ini`:
```ini
[TRANSLATION]
use_8bit = true
```

Or use CPU:
```ini
[TRANSLATION]
device = cpu
```

### Issue: "ChromaDB collection empty"

**Solution**: Rebuild the vector database:
```bash
python build_vector_db.py --clear_existing --config config.ini
```

### Issue: "Poor translation quality"

**Solutions**:
1. Increase `top_k` to retrieve more examples
2. Ensure `economic v1.csv` is properly loaded
3. Try different translation models
4. Check if RAG is enabled (`use_context=True`)

---

## ğŸ“ˆ Performance Tips

### For Speed
- Use FAISS instead of ChromaDB
- Enable GPU acceleration
- Use 8-bit quantization
- Reduce `top_k` to 3-5

### For Quality
- Increase `top_k` to 7-10
- Use larger translation models (NLLB)
- Ensure diverse training corpus
- Fine-tune on domain-specific data

### For Memory Efficiency
- Enable 4-bit quantization
- Use smaller embedding models
- Reduce batch sizes
- Use CPU if limited VRAM

---

## ğŸ”¬ How the Agentic System Works

### Agent Decision Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Input: English text to translate        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT DECISION 1: Text Analysis                 â”‚
â”‚ â€¢ Analyze semantic content                      â”‚
â”‚ â€¢ Identify domain (economic, legal, etc.)       â”‚
â”‚ â€¢ Determine complexity                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT DECISION 2: Retrieval Strategy            â”‚
â”‚ â€¢ How many examples to retrieve? (top_k)        â”‚
â”‚ â€¢ Should we filter by domain?                   â”‚
â”‚ â€¢ What similarity threshold?                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ACTION: Query Vector Database                   â”‚
â”‚ â€¢ Search economic v1.csv embeddings             â”‚
â”‚ â€¢ Rank by semantic similarity                   â”‚
â”‚ â€¢ Return top-k most relevant examples           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT DECISION 3: Context Selection              â”‚
â”‚ â€¢ Evaluate retrieved examples                   â”‚
â”‚ â€¢ Filter out low-quality matches                â”‚
â”‚ â€¢ Order by relevance                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT DECISION 4: Prompt Construction            â”‚
â”‚ â€¢ Format selected examples                      â”‚
â”‚ â€¢ Build context-aware prompt                    â”‚
â”‚ â€¢ Include domain-specific instructions          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT DECISION 5: Generation Strategy            â”‚
â”‚ â€¢ Select temperature for creativity             â”‚
â”‚ â€¢ Choose beam width for quality                 â”‚
â”‚ â€¢ Determine max length                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ACTION: Generate Translation                     â”‚
â”‚ â€¢ Input: Context + Source text                  â”‚
â”‚ â€¢ Process: Neural translation with context      â”‚
â”‚ â€¢ Output: Arabic translation                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT DECISION 6: Post-Processing                â”‚
â”‚ â€¢ Validate output quality                       â”‚
â”‚ â€¢ Normalize Arabic text                         â”‚
â”‚ â€¢ Check for errors                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Output: Context-aware translation        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Agentic Behaviors

1. **Autonomous Reasoning**: Makes decisions without human intervention at each step
2. **Context Awareness**: Understands when to use which examples based on semantic similarity
3. **Adaptive Strategy**: Adjusts parameters based on input characteristics
4. **Goal-Oriented**: Works towards producing the best domain-specific translation
5. **Self-Monitoring**: Validates outputs and can retry with different parameters

---

## ğŸ“š Key Concepts

### RAG (Retrieval-Augmented Generation)
A technique that enhances language models by retrieving relevant information from external knowledge sources before generation. In this case, we retrieve similar translation examples from `economic v1.csv`.

### Vector Database
A specialized database that stores high-dimensional vectors (embeddings) and enables fast similarity search. Our economic corpus is embedded and indexed here.

### Semantic Search
Finding similar texts based on meaning rather than exact word matches. Powered by sentence embeddings.

### Few-Shot Learning
Providing the model with examples (from retrieved context) to guide translation, improving domain-specific accuracy.

---

## ğŸ“ Citation

If you use this system in research, please cite:

```bibtex
@software{rag_translation_agent,
  title={RAG Translation Agent: Context-Specific Machine Translation to Arabic},
  author={Your Name},
  year={2024},
  url={https://github.com/yourusername/your-repo}
}
```

---

## ğŸ“ License

This project is licensed under the MIT License. The UN parallel corpus (`economic v1.csv`) may have separate licensing terms.

---

## ğŸ¤ Contributing

Contributions are welcome! Areas for improvement:

- Additional translation models
- More evaluation metrics
- Domain expansion beyond economics
- Multi-language support
- Fine-tuning scripts

---

## ğŸ“ Support

For issues, questions, or suggestions:
- Open an issue on GitHub
- Check the troubleshooting section
- Review example scripts

---

## ğŸ“‚ Complete File Structure

```
RAG_Agent/
â”œâ”€â”€ ğŸ“„ README.md              â† You are here! Complete documentation
â”‚
â”œâ”€â”€ ğŸ”§ Core Components
â”‚   â”œâ”€â”€ rag_agent.py          â† RAG orchestrator (agentic logic)
â”‚   â”œâ”€â”€ vector_db.py          â† Vector database manager
â”‚   â””â”€â”€ utils.py              â† Helper functions
â”‚
â”œâ”€â”€ ğŸ› ï¸ Scripts & Tools
â”‚   â”œâ”€â”€ build_vector_db.py    â† Build vector DB from economic v1.csv
â”‚   â”œâ”€â”€ evaluate.py           â† Evaluation suite
â”‚   â”œâ”€â”€ app.py                â† Streamlit web interface
â”‚   â”œâ”€â”€ example.py            â† Usage examples
â”‚   â””â”€â”€ check_gpu.py          â† GPU diagnostics
â”‚
â”œâ”€â”€ ğŸ“Š Data
â”‚   â””â”€â”€ economic v1.csv       â† UN parallel corpus (EN-AR)
â”‚
â”œâ”€â”€ âš™ï¸ Configuration
â”‚   â”œâ”€â”€ config.ini            â† System configuration
â”‚   â”œâ”€â”€ requirements.txt      â† Python dependencies
â”‚   â”œâ”€â”€ setup.fish            â† Setup script (Fish shell)
â”‚   â””â”€â”€ setup.sh              â† Setup script (Bash)
â”‚
â””â”€â”€ ğŸ—‚ï¸ Generated (after setup)
    â”œâ”€â”€ vector_db/            â† Vector database storage
    â”œâ”€â”€ logs/                 â† Application logs
    â””â”€â”€ venv/                 â† Python virtual environment
```

---

## ğŸ‰ Summary

You now have a complete RAG-based translation system that:

âœ… Uses `economic v1.csv` as knowledge base  
âœ… Performs semantic retrieval for context  
âœ… Acts as an intelligent agent with autonomous decision-making  
âœ… Delivers domain-specific, consistent translations  
âœ… Supports multiple models and configurations  
âœ… Provides web UI and Python API  
âœ… Includes comprehensive evaluation tools  
âœ… Offers GPU acceleration for performance  

**Ready to translate!** ğŸš€
